{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Sklearn ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, get_scorer_names\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle as pkl\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize k-fold value\n",
    "k=5\n",
    "# Initialize variable for first test/train split\n",
    "#test_percent = 1/(k+1)\n",
    "test_percent = 0.2\n",
    "print(test_percent)\n",
    "\n",
    "# Mahalanobis threshold\n",
    "m_thresh = 0.05\n",
    "\n",
    "# Use same random seed to ensure reproducible results across runs\n",
    "rand_seed = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>class</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f1014</th>\n",
       "      <th>f1015</th>\n",
       "      <th>f1016</th>\n",
       "      <th>f1017</th>\n",
       "      <th>f1018</th>\n",
       "      <th>f1019</th>\n",
       "      <th>f1020</th>\n",
       "      <th>f1021</th>\n",
       "      <th>f1022</th>\n",
       "      <th>f1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZYURRE527</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.284965</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680631</td>\n",
       "      <td>-1.153061</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.162622</td>\n",
       "      <td>-1.085265</td>\n",
       "      <td>-0.657002</td>\n",
       "      <td>-1.406191</td>\n",
       "      <td>2.240085</td>\n",
       "      <td>0.118616</td>\n",
       "      <td>-0.728013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZWNWBP435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.045820</td>\n",
       "      <td>-0.216762</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.241972</td>\n",
       "      <td>-0.115316</td>\n",
       "      <td>-0.411191</td>\n",
       "      <td>0.431461</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>1.243681</td>\n",
       "      <td>-0.151721</td>\n",
       "      <td>0.458508</td>\n",
       "      <td>1.931918</td>\n",
       "      <td>-0.241081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZVHEZA963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>-0.292385</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>-0.792833</td>\n",
       "      <td>-0.471358</td>\n",
       "      <td>0.514799</td>\n",
       "      <td>-0.846220</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>-0.730218</td>\n",
       "      <td>1.352716</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.163302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ZSFNU1100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>-0.109248</td>\n",
       "      <td>-0.183284</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047666</td>\n",
       "      <td>-0.201043</td>\n",
       "      <td>-0.565545</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>-0.332314</td>\n",
       "      <td>-0.066972</td>\n",
       "      <td>-1.263785</td>\n",
       "      <td>3.876905</td>\n",
       "      <td>-0.397950</td>\n",
       "      <td>-0.693763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ZRXUB1049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>-0.068301</td>\n",
       "      <td>-0.283487</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221178</td>\n",
       "      <td>-0.253239</td>\n",
       "      <td>-0.046740</td>\n",
       "      <td>0.242367</td>\n",
       "      <td>-0.379724</td>\n",
       "      <td>-0.893249</td>\n",
       "      <td>-0.957397</td>\n",
       "      <td>1.118245</td>\n",
       "      <td>0.181925</td>\n",
       "      <td>-0.024197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>AGHXWX765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>-0.093583</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260746</td>\n",
       "      <td>-0.741712</td>\n",
       "      <td>-0.887129</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>0.216271</td>\n",
       "      <td>0.490549</td>\n",
       "      <td>-1.047399</td>\n",
       "      <td>1.875185</td>\n",
       "      <td>0.345561</td>\n",
       "      <td>-0.874318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>AFEOPC672</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>-0.302020</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457373</td>\n",
       "      <td>-0.782917</td>\n",
       "      <td>-1.072765</td>\n",
       "      <td>1.180279</td>\n",
       "      <td>-0.111142</td>\n",
       "      <td>1.897755</td>\n",
       "      <td>-0.902370</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>-0.314270</td>\n",
       "      <td>-1.198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>AEEEIG737</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>-0.152744</td>\n",
       "      <td>-0.355706</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411773</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>-0.527885</td>\n",
       "      <td>-0.305296</td>\n",
       "      <td>-0.189008</td>\n",
       "      <td>-0.592684</td>\n",
       "      <td>-1.144780</td>\n",
       "      <td>3.459698</td>\n",
       "      <td>-0.199579</td>\n",
       "      <td>-0.999165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>425</td>\n",
       "      <td>ADQRPH513</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>-0.092386</td>\n",
       "      <td>-0.434045</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147889</td>\n",
       "      <td>1.168724</td>\n",
       "      <td>-0.486698</td>\n",
       "      <td>1.134707</td>\n",
       "      <td>-0.029372</td>\n",
       "      <td>0.092189</td>\n",
       "      <td>-0.791921</td>\n",
       "      <td>1.786787</td>\n",
       "      <td>2.089036</td>\n",
       "      <td>-0.690614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>ABNTSS552</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.047733</td>\n",
       "      <td>-0.071875</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064665</td>\n",
       "      <td>-0.444786</td>\n",
       "      <td>-0.879349</td>\n",
       "      <td>1.048909</td>\n",
       "      <td>0.213126</td>\n",
       "      <td>1.170847</td>\n",
       "      <td>-1.172747</td>\n",
       "      <td>1.686595</td>\n",
       "      <td>0.482523</td>\n",
       "      <td>-0.440434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        uid  class        f0        f1        f2        f3  \\\n",
       "0             0  ZYURRE527      4  0.000462  0.005583 -0.001031  0.002307   \n",
       "1             1  ZWNWBP435      0  0.000220  0.006780 -0.000547  0.002183   \n",
       "2             2  ZVHEZA963      4  0.000405  0.007183 -0.000137  0.002612   \n",
       "3             3  ZSFNU1100      4  0.000388  0.003802  0.002121  0.001513   \n",
       "4             4  ZRXUB1049      0  0.000425  0.006544  0.001630  0.001549   \n",
       "..          ...        ...    ...       ...       ...       ...       ...   \n",
       "422         422  AGHXWX765      0  0.000305  0.003671 -0.004093  0.003010   \n",
       "423         423  AFEOPC672      3  0.000441  0.006178 -0.000811  0.003572   \n",
       "424         424  AEEEIG737      3  0.000464  0.006611  0.000842  0.001412   \n",
       "425         425  ADQRPH513      3  0.000233  0.003029  0.001606  0.001224   \n",
       "426         426  ABNTSS552      4  0.000233  0.006601 -0.001318  0.001098   \n",
       "\n",
       "           f4        f5        f6  ...     f1014     f1015     f1016  \\\n",
       "0   -0.113097 -0.284965  0.001069  ...  0.680631 -1.153061  0.111816   \n",
       "1   -0.045820 -0.216762  0.000987  ... -1.241972 -0.115316 -0.411191   \n",
       "2   -0.083430 -0.292385  0.001094  ...  0.659314 -0.792833 -0.471358   \n",
       "3   -0.109248 -0.183284  0.000813  ... -0.047666 -0.201043 -0.565545   \n",
       "4   -0.068301 -0.283487  0.001004  ... -1.221178 -0.253239 -0.046740   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "422 -0.093583  0.133018  0.000627  ... -0.260746 -0.741712 -0.887129   \n",
       "423 -0.108863 -0.302020  0.000761  ...  0.457373 -0.782917 -1.072765   \n",
       "424 -0.152744 -0.355706  0.000906  ...  0.411773  0.232481 -0.527885   \n",
       "425 -0.092386 -0.434045  0.000668  ... -0.147889  1.168724 -0.486698   \n",
       "426 -0.047733 -0.071875  0.000654  ... -0.064665 -0.444786 -0.879349   \n",
       "\n",
       "        f1017     f1018     f1019     f1020     f1021     f1022     f1023  \n",
       "0    0.162622 -1.085265 -0.657002 -1.406191  2.240085  0.118616 -0.728013  \n",
       "1    0.431461  0.442649  1.243681 -0.151721  0.458508  1.931918 -0.241081  \n",
       "2    0.514799 -0.846220  0.479314 -0.730218  1.352716  0.040223 -0.163302  \n",
       "3    0.999009 -0.332314 -0.066972 -1.263785  3.876905 -0.397950 -0.693763  \n",
       "4    0.242367 -0.379724 -0.893249 -0.957397  1.118245  0.181925 -0.024197  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "422  0.190525  0.216271  0.490549 -1.047399  1.875185  0.345561 -0.874318  \n",
       "423  1.180279 -0.111142  1.897755 -0.902370  0.552967 -0.314270 -1.198762  \n",
       "424 -0.305296 -0.189008 -0.592684 -1.144780  3.459698 -0.199579 -0.999165  \n",
       "425  1.134707 -0.029372  0.092189 -0.791921  1.786787  2.089036 -0.690614  \n",
       "426  1.048909  0.213126  1.170847 -1.172747  1.686595  0.482523 -0.440434  \n",
       "\n",
       "[427 rows x 1027 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in dataset\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of feature names\n",
    "feature_names = [name for name in df.columns if name.startswith(\"f\")]\n",
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    127\n",
       "4     87\n",
       "3     62\n",
       "1     43\n",
       "2     22\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    32\n",
       "4    22\n",
       "3    16\n",
       "1    11\n",
       "2     5\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = df[feature_names]\n",
    "y_all = df[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_percent, random_state=rand_seed, stratify=y_all\n",
    ")\n",
    "\n",
    "# Reset train index\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Training set by class:\")\n",
    "display(y_train.value_counts())\n",
    "print(\"Test set by class:\")\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Data\n",
    "\n",
    "Use StandardScaler from sklearn. Standardize both X_train and X_test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scaler\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "# Fit and transform scaling to training data\n",
    "X_train = scaler_std.fit_transform(X_train)\n",
    "# Transform testing data using same fit\n",
    "X_test = scaler_std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store scaler_std so we can transform the blind test data in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'scaler_std' (StandardScaler)\n"
     ]
    }
   ],
   "source": [
    "%store scaler_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get single training DataFrame\n",
    "# norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "# norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "# # Standardize X_train values\n",
    "# X_train = norm_data(norm_df[feature_names])\n",
    "\n",
    "# # Get single testing DataFrame\n",
    "# norm_xtest_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "# norm_test_df = pd.concat([y_test, norm_x_df], axis=1)\n",
    "# # Standardize X_test values (for later)\n",
    "# X_test = norm_data(norm_test_df[feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers\n",
    "\n",
    "Since we are in multi-dimensional space, we will use the mean and covariance matrices. This will be computed using Mahalanobis distance which is well-suited for multi-dimensional space: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that computes mean, cov matrix, and inv cov matrix\n",
    "def get_mean_cov(X_train):\n",
    "    # Merge dfs\n",
    "    norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "    norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "    # Compute mean and cov per class per feature\n",
    "    avg_list = []\n",
    "    cov_list = []\n",
    "    inv_cov_list = []\n",
    "    for i in range(5):\n",
    "        # Compute mean\n",
    "        avg = np.mean(norm_df[norm_df[\"class\"]==i][feature_names], axis=0)\n",
    "        avg_list.append(avg)\n",
    "        # Compute cov matrix\n",
    "        cov = np.cov(norm_df[norm_df[\"class\"]==i][feature_names], rowvar=False)\n",
    "        cov_list.append(cov)\n",
    "        # Compute inverse of cov matrix\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        inv_cov_list.append(inv_cov)\n",
    "    return norm_df, avg_list, inv_cov_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_mean_cov function\n",
    "norm_df, avg_list, inv_cov_list = get_mean_cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    341.000000\n",
       "mean      20.151181\n",
       "std       10.312641\n",
       "min        0.483079\n",
       "25%       12.904636\n",
       "50%       18.458333\n",
       "75%       25.709080\n",
       "max       57.741092\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which features should be removed (identify outliers based on Mahalanobis dist)\n",
    "# Create function that computes Mahalanobis distance and adds it to norm_df\n",
    "def get_mahalanobis_dist(label, features):\n",
    "    u = avg_list[label]\n",
    "    v = features\n",
    "    vi = inv_cov_list[label]\n",
    "    delta = u - v\n",
    "    m = np.dot(np.dot(delta, vi), delta)\n",
    "    #dist = distance.mahalanobis(u, features, vi)\n",
    "    return np.sqrt(np.abs(m))\n",
    "\n",
    "# Call function for each feature\n",
    "norm_df[\"mahalanobis_dist\"] = norm_df.apply(lambda row: get_mahalanobis_dist(int(row[\"class\"]), row[feature_names]), axis=1)\n",
    "norm_df[\"mahalanobis_dist\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "def drop_outliers(norm_df, threshold):\n",
    "    # Remove threshold% of outliers by class\n",
    "    for i in range(5):\n",
    "        # Get threshold% of outliers for each class\n",
    "        threshold_num = norm_df[norm_df[\"class\"]==i][\"mahalanobis_dist\"].quantile(1-threshold)\n",
    "        # Drop threshold% of outliers for each class\n",
    "        norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)        \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\AppData\\Local\\Temp\\ipykernel_36440\\977542497.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    320.000000\n",
       "mean      18.976607\n",
       "std        9.113965\n",
       "min        0.483079\n",
       "25%       12.525085\n",
       "50%       17.800747\n",
       "75%       24.270619\n",
       "max       44.937688\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test drop_outliers function\n",
    "norm_df = drop_outliers(norm_df, m_thresh)\n",
    "\n",
    "# Print updated descriptive stats\n",
    "norm_df[\"mahalanobis_dist\"].describe()\n",
    "#print(len(norm_df[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X_train and y_train\n",
    "X_train = norm_df[feature_names]\n",
    "y_train = norm_df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample Data\n",
    "\n",
    "Use ADASYN technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that oversamples or undersamples data\n",
    "def resample(sampler, X_train, y_train, name):\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "    # Observe number of classes after resample\n",
    "    #print(f\"Number of samples per class after {name}:\\n{y_train.value_counts()}\")\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resample function\n",
    "# Setup ADASYN (oversampling)\n",
    "ada = ADASYN(random_state=rand_seed, sampling_strategy=\"minority\", n_neighbors=4)\n",
    "\n",
    "# Call resample function\n",
    "X_train, y_train = resample(ada, X_train, y_train, \"ADASYN Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 1024)\n",
      "0    120\n",
      "2    120\n",
      "4     82\n",
      "3     58\n",
      "1     40\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "# List from Azure ML Designer (Filter Based Feature Selection)\n",
    "azureml_features = pd.read_csv(\"outputs/feature_selection/azureml_designer_features.csv\", header=None)\n",
    "# List from recursive feature elimination w/ and w/o cross-validation\n",
    "rfe_features = pd.read_csv(\"outputs/feature_selection/CommonFeatures_RFE_RFECV.csv\", header=None)\n",
    "\n",
    "rfe_features = rfe_features[0].to_numpy()\n",
    "#display(rfe_features)\n",
    "azureml_features = azureml_features[0].to_numpy()\n",
    "# display(azureml_features)\n",
    "\n",
    "# Get out common features\n",
    "common_features = np.union1d(azureml_features, rfe_features)\n",
    "extracted_feature_names = [f\"f{i}\" for i in common_features]\n",
    "extracted_feature_names_nof = [f\"{i}\" for i in common_features]\n",
    "#print(extracted_feature_names)\n",
    "#display(extracted_feature_names)\n",
    "print(np.count_nonzero(common_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store extracted_feature_names for use in inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'common_features' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store common_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'extracted_feature_names_nof' (list)\n"
     ]
    }
   ],
   "source": [
    "%store extracted_feature_names_nof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training dataset with only\n",
    "# the subset of features included\n",
    "X_train = X_train[extracted_feature_names]\n",
    "#print(X_train)\n",
    "\n",
    "# Get testing dataset wiuth only\n",
    "# the subset of features included\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test = X_test[extracted_feature_names]\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters to try\n",
    "c_range = np.arange(5,4000)\n",
    "params = {\n",
    "    'C': c_range,\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Setup classifier\n",
    "svm = SVC(random_state=rand_seed)\n",
    "# Configure random search from sklearn\n",
    "svm_clf = RandomizedSearchCV(svm, params, scoring='f1_macro', cv=k, random_state=rand_seed)\n",
    "# Perform hyperparameter search\n",
    "search = svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 'auto', 'C': 721}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374713</td>\n",
       "      <td>0.087836</td>\n",
       "      <td>0.111471</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>721</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 721}</td>\n",
       "      <td>0.672246</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>0.608016</td>\n",
       "      <td>0.040726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277333</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.080140</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>303</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 303}</td>\n",
       "      <td>0.635996</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328003</td>\n",
       "      <td>0.054777</td>\n",
       "      <td>0.104672</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>1596</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}</td>\n",
       "      <td>0.672246</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>0.608016</td>\n",
       "      <td>0.040726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326114</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>0.102429</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>931</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 931}</td>\n",
       "      <td>0.635996</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.284282</td>\n",
       "      <td>0.052315</td>\n",
       "      <td>0.082928</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>382</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 382}</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.654875</td>\n",
       "      <td>0.568691</td>\n",
       "      <td>0.600762</td>\n",
       "      <td>0.605457</td>\n",
       "      <td>0.027776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.370081</td>\n",
       "      <td>0.031572</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.018381</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2022</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}</td>\n",
       "      <td>0.635996</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.336079</td>\n",
       "      <td>0.069949</td>\n",
       "      <td>0.103274</td>\n",
       "      <td>0.024040</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>2352</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}</td>\n",
       "      <td>0.672246</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>0.608016</td>\n",
       "      <td>0.040726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.069574</td>\n",
       "      <td>0.094240</td>\n",
       "      <td>0.027231</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>650</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 650}</td>\n",
       "      <td>0.635996</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.378544</td>\n",
       "      <td>0.039751</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>3159</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}</td>\n",
       "      <td>0.635996</td>\n",
       "      <td>0.638922</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.575191</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.332630</td>\n",
       "      <td>0.069962</td>\n",
       "      <td>0.097653</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>1969</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 1969}</td>\n",
       "      <td>0.603704</td>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.654875</td>\n",
       "      <td>0.568691</td>\n",
       "      <td>0.600762</td>\n",
       "      <td>0.605457</td>\n",
       "      <td>0.027776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.374713      0.087836         0.111471        0.026423          rbf   \n",
       "1       0.277333      0.024490         0.080140        0.003745          rbf   \n",
       "2       0.328003      0.054777         0.104672        0.025466          rbf   \n",
       "3       0.326114      0.042793         0.102429        0.022790          rbf   \n",
       "4       0.284282      0.052315         0.082928        0.012562       linear   \n",
       "5       0.370081      0.031572         0.114876        0.018381          rbf   \n",
       "6       0.336079      0.069949         0.103274        0.024040          rbf   \n",
       "7       0.340260      0.069574         0.094240        0.027231          rbf   \n",
       "8       0.378544      0.039751         0.115470        0.034116          rbf   \n",
       "9       0.332630      0.069962         0.097653        0.025981       linear   \n",
       "\n",
       "  param_gamma param_C                                            params  \\\n",
       "0        auto     721      {'kernel': 'rbf', 'gamma': 'auto', 'C': 721}   \n",
       "1       scale     303     {'kernel': 'rbf', 'gamma': 'scale', 'C': 303}   \n",
       "2        auto    1596     {'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}   \n",
       "3       scale     931     {'kernel': 'rbf', 'gamma': 'scale', 'C': 931}   \n",
       "4        auto     382   {'kernel': 'linear', 'gamma': 'auto', 'C': 382}   \n",
       "5       scale    2022    {'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}   \n",
       "6        auto    2352     {'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}   \n",
       "7       scale     650     {'kernel': 'rbf', 'gamma': 'scale', 'C': 650}   \n",
       "8       scale    3159    {'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}   \n",
       "9        auto    1969  {'kernel': 'linear', 'gamma': 'auto', 'C': 1969}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.672246           0.638922           0.586695           0.575191   \n",
       "1           0.635996           0.638922           0.587079           0.575191   \n",
       "2           0.672246           0.638922           0.586695           0.575191   \n",
       "3           0.635996           0.638922           0.587079           0.575191   \n",
       "4           0.603704           0.599252           0.654875           0.568691   \n",
       "5           0.635996           0.638922           0.587079           0.575191   \n",
       "6           0.672246           0.638922           0.586695           0.575191   \n",
       "7           0.635996           0.638922           0.587079           0.575191   \n",
       "8           0.635996           0.638922           0.587079           0.575191   \n",
       "9           0.603704           0.599252           0.654875           0.568691   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.567025         0.608016        0.040726                1  \n",
       "1           0.567759         0.600989        0.030423                6  \n",
       "2           0.567025         0.608016        0.040726                1  \n",
       "3           0.567759         0.600989        0.030423                6  \n",
       "4           0.600762         0.605457        0.027776                4  \n",
       "5           0.567759         0.600989        0.030423                6  \n",
       "6           0.567025         0.608016        0.040726                1  \n",
       "7           0.567759         0.600989        0.030423                6  \n",
       "8           0.567759         0.600989        0.030423                6  \n",
       "9           0.600762         0.605457        0.027776                4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_params)\n",
    "#display(search.cv_results_)\n",
    "\n",
    "hyperparam_results_df = pd.DataFrame(search.cv_results_)\n",
    "display(hyperparam_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_classifier_with_k_folds(classifier, n_splits=5, random_state=rand_seed):\n",
    "    classifiers = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        classifiers.append(classifier)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_fold)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "        precision_scores.append(\n",
    "            precision_score(y_test_fold, y_pred, average=\"macro\")\n",
    "        )\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "\n",
    "    return classifiers, {\n",
    "        \"accuracy\": pd.Series(accuracy_scores).describe().to_dict(),\n",
    "        \"f1\": pd.Series(f1_scores).describe().to_dict(),\n",
    "        \"precision\": pd.Series(precision_scores).describe().to_dict(),\n",
    "        \"recall\": pd.Series(recall_scores).describe().to_dict(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SVC(C=721, gamma='auto', random_state=255),\n",
       "  SVC(C=721, gamma='auto', random_state=255),\n",
       "  SVC(C=721, gamma='auto', random_state=255),\n",
       "  SVC(C=721, gamma='auto', random_state=255),\n",
       "  SVC(C=721, gamma='auto', random_state=255)],\n",
       " {'accuracy': {'count': 5.0,\n",
       "   'mean': 0.6976190476190476,\n",
       "   'std': 0.04259177099999598,\n",
       "   'min': 0.6547619047619048,\n",
       "   '25%': 0.6547619047619048,\n",
       "   '50%': 0.7023809523809523,\n",
       "   '75%': 0.7261904761904762,\n",
       "   'max': 0.75},\n",
       "  'f1': {'count': 5.0,\n",
       "   'mean': 0.6038777970976675,\n",
       "   'std': 0.05180045904451835,\n",
       "   'min': 0.559144385026738,\n",
       "   '25%': 0.5600945043656907,\n",
       "   '50%': 0.5951012223071046,\n",
       "   '75%': 0.6208615567439096,\n",
       "   'max': 0.6841873170448947},\n",
       "  'precision': {'count': 5.0,\n",
       "   'mean': 0.6694601558372415,\n",
       "   'std': 0.03019592640598982,\n",
       "   'min': 0.6295970695970695,\n",
       "   '25%': 0.6532155657962109,\n",
       "   '50%': 0.6660727086533538,\n",
       "   '75%': 0.6966666666666667,\n",
       "   'max': 0.7017487684729063},\n",
       "  'recall': {'count': 5.0,\n",
       "   'mean': 0.5944830659536542,\n",
       "   'std': 0.052734747619834973,\n",
       "   'min': 0.548663101604278,\n",
       "   '25%': 0.55,\n",
       "   '50%': 0.5833333333333333,\n",
       "   '75%': 0.6154188948306596,\n",
       "   'max': 0.675}})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "analyze_classifier_with_k_folds(svm_final_clf, n_splits=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5233\n",
      "F1 macro score: 0.5384\n",
      "Precision: 0.6016\n",
      "Recall: 0.5098\n"
     ]
    }
   ],
   "source": [
    "# Fit model using best hyperparameters found in previous search\n",
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "svm_model_final = svm_final_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model_final.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 macro score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model for use in inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'svm_model_final' (SVC)\n"
     ]
    }
   ],
   "source": [
    "%store svm_model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as pickle\n",
    "s = pkl.dumps(svm_model_final)\n",
    "dump(svm_model_final, \"svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Meta Learning!\n",
    "\n",
    "In addition to the svm classifier above (svm), we'll use the VotingClassifier() from sklearn which takes multiple estimators as input, and implements a voting procedure. We will use the following classifiers:\n",
    "\n",
    "- SVM (already created)\n",
    "- Naive Bayes\n",
    "- kNN, k=5\n",
    "- Decision Tree, max depth = 8\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the classifiers!\n",
    "# Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# kNN, k=5\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Decision tree, max depth=8\n",
    "dt_clf = DecisionTreeClassifier(random_state=rand_seed, max_depth=8)\n",
    "\n",
    "# Logistic regression\n",
    "lr_clf = LogisticRegression(random_state=rand_seed, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.5000\n",
      "Ensemble F1 macro score: 0.4838\n",
      "Ensemble precision: 0.5734\n",
      "Ensemble recall: 0.5020\n"
     ]
    }
   ],
   "source": [
    "# Put them to a vote!\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), ('nb', nb_clf), ('knn', knn_clf),\n",
    "    ('dt', dt_clf), ('lr', lr_clf)], voting='hard'\n",
    ")\n",
    "\n",
    "# Fit and predict with voting classifier\n",
    "ensemble_clf = ensemble_clf.fit(X_train, y_train)\n",
    "ensemble_pred = ensemble_clf.predict(X_test)\n",
    "\n",
    "# Get metrics\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_precision = precision_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_recall = recall_score(y_test, ensemble_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Ensemble accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"Ensemble F1 macro score: {ensemble_f1:.4f}\")\n",
    "print(f\"Ensemble precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Ensemble recall: {ensemble_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a15761a860>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAG2CAYAAACNs6TQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiWklEQVR4nO3deVxUVf8H8M8wAzNsM+wIiogboogLmKJploqhmbbaY6kVWqZlZitZuTwW1a/HsAWXFs1WK00tSaXFPVMQN8AdBZFd9mVgZu7vD3JsZNCBYRhm5vN+vW6v5nDOvd97nZnvnHPPvVckCIIAIiIisgp25g6AiIiIWg8TOxERkRVhYiciIrIiTOxERERWhImdiIjIijCxExERWREmdiIiIivCxE5ERGRFmNiJiIisCBM7ERGRFWFiJyIiMqGEhAQEBQVBJpMhPDwce/bsuWH9r7/+Gv369YOTkxP8/Pzw2GOPobi42ODtMbETERGZyPr16zFv3jwsWLAAqampGD58OKKjo5GVlaW3/t69ezFt2jTExMQgLS0NP/zwAw4dOoQZM2YYvE0RHwJDRERkGoMHD8bAgQOxYsUKbVlISAgmTZqEuLi4RvXfe+89rFixAufOndOWffjhh3j33XeRnZ1t0DYlxodtPhqNBpcvX4arqytEIpG5wyEiomYSBAEVFRXw9/eHnZ3pBpFra2tRV1dn9HoEQWiUb6RSKaRSaaO6dXV1SElJwSuvvKJTHhUVhf379+td/9ChQ7FgwQIkJiYiOjoaBQUF+PHHHzF+/PhmBWmxsrOzBQBcuHDhwsXCl+zsbJPlipqaGqGDj7hV4nRxcWlUtnDhQr3bzcnJEQAI+/bt0yl/8803hZ49ezYZ7w8//CC4uLgIEolEACDcfffdQl1dncH7a9E9dldXVwBA/O7+cHQRmzma9u3bgZ3MHYJFEAd3M3cIFkHj0rh3Qo3ZVSrNHUK7p1Irsevsx9rvc1Ooq6tDXoEaF1O6QO7a8lGB8goNAsMvIDs7G3K5XFuur7f+b9f38AU9vf6r0tPTMXfuXLzxxhsYO3YscnNz8eKLL2LWrFn47LPPDIrTohP71QPj6CKGo4tF74rJSUT25g7BIojFTFiG0Ihl5g7BItixv2Gwtjid6uIqgotry7ejQUNbuVyuk9ib4uXlBbFYjLy8PJ3ygoIC+Pr66m0TFxeHYcOG4cUXXwQAhIWFwdnZGcOHD8fSpUvh5+d30+1yVjwREdkEtaAxemkOBwcHhIeHIykpSac8KSkJQ4cO1dumurq60VwDsbjhF6Jg4Fx3dnOJiMgmaCBAA8OSY1Ptm2v+/PmYOnUqIiIiEBkZidWrVyMrKwuzZs0CAMTGxiInJwfr1q0DAEyYMAEzZ87EihUrtEPx8+bNwy233AJ/f3+DtsnETkREZCKTJ09GcXExlixZgtzcXISGhiIxMRGBgYEAgNzcXJ1r2h999FFUVFTgo48+wvPPPw83NzfccccdeOeddwzepkVfx15eXg6FQoFVh8N5jv0m1gUHmDsEiyAO6WHuECyCxoXn2A1hV1lr7hDaPZVaid9PLUNZWZlB561b4mquuHyqk9GT5/yDL5k01tbAbEhERDZBLQhQG9GXNaZtW+LkOSIiIivCHjsREdkEc0yeMwcmdiIisgkaCFDbQGLnUDwREZEVYY+diIhsAofiiYiIrAhnxRMREZHFYY+diIhsguafxZj2loCJnYiIbILayFnxxrRtS0zsRERkE9RCw2JMe0vAc+xERERWhD12IiKyCTzHTkREZEU0EEENkVHtLQGH4omIiKwIe+xERGQTNELDYkx7S8DETkRENkFt5FC8MW3bEofiiYiIrAh77EREZBNspcfOxE5ERDZBI4igEYyYFW9E27bEoXgiIiIrwh47ERHZBA7FExERWRE17KA2YqBa3YqxmBITOxER2QTByHPsgoWcY2div4mTX7sg/TNXVBeK4dajHoNeLYFvRF2T9dV1wLGPFTi/xQk1hWI4dVCj76xy9Li/CgCgqQeOr5Lj3CZnVOeLoQiqx8AXytBxRG1b7ZLZ3TW9CA88VQgPn3pcPC3Dyjf8ceKgi7nDMonxd5/DfQ+egodnLS5ekGN1Qj+kHfdusn5oWCFmPnUUgV3KUVzkiA3reyLxl27av4vFGjw45SRGR12Ep1cNLmW7Ys0nfZFyqIPe9T34n5N4dMYJbNrQHasT+rf27pnMXdGncP896fBwr8HFLDes/CwCaek+eut6uFdj5mOH0aN7Mfz9KrD5l15Y9VmETp07x5zB6NvPIzCwDABw9pwH1nzZH6fPeJl8X1oT309kCE6eu4HMREckx7mh71PluGtTHnzDlfh9pjcqL4ubbLPrWS/k/iVF5JtXMGlbLkYsK4aia73276nxCpxe74xbXi/BxMRc9HyoEjuf9kRxun1b7JLZ3XZ3CWYtvoxvP/DB7KieOPG3M5Z+nQnvjk3/WLJUI0Zm44nZR7D+mxA88+RopB33wpK4vfD2qdZb37dDFZa8tRdpx73wzJOj8f23vfDk00cwbPglbZ1pj59A9F3nseLD/pj1eBQSf+6K1xbvR9fuJY3W1yP4Cu4cfx7nzylMto+mMOLWC3gyJgXf/RCKOc+Nx4l0Hyx94w94e1XprW9vr0FZuRTf/tAX5y+4660T1jcfO/d0wcuvjcZzL41FQaEz3lr0Ozw99P9btEd8Pxnv6jl2YxZLYPbEnpCQgKCgIMhkMoSHh2PPnj3mDkkrY40rut9XhR4PVMGtmwqDFpTCuYMap7/V37vM2S1D/iEpRq0ugv9QJVw6qeEVVgefgdeS1vnNzug7qwKdbquFa4AawVOq4H9rLdI/d22r3TKre58owvZvPbDtG09kn5Vh5cKOKLxsj7umFZs7tFZ3z/2nsePXIGxPDEJ2lhyrE/qjsMAJ4yec01t/3IRzKChwwuqE/sjOkmN7YhCStgXh3gdPa+vcMToL33/TC8kH/ZCX64LEn7vhcHIH3PvAGZ11yWQqvPTqQXywLByVFZb1o/HeiRnY/ls3bEvqgexLCqz6LAKFRU64K/q03vr5BS5Y+ekg/P5nV1RX6d/Xd5fdil9+Dcb5TA9cylFg+ceDIbID+vfLM+WutCq+n4ynFuyMXiyBWaNcv3495s2bhwULFiA1NRXDhw9HdHQ0srKyzBkWgIYh9eI0B/jfqjtE7jesFoWpDnrbZP/hCM/QOpz41BU/DPfDT2M7IPkdBVS1137lqesBsYPuDYfFMgEFh6WtvxPtjMRegx5h1UjZpfsjJmWXK3pH6O+NWSqJRIPuPUtxONlXpzw1xRchffT/iAnpfQWpKbr1Uw75okfPEojFDQ+MtHfQoK5Od8RIqRSjT2iRTtnsZ1Nx8EAHHDmsu772TiJRo0e3Kzh8xE+n/PARP4T0Kmy17UilakjEGlRU6P8stzd8P1FzmDWxL1u2DDExMZgxYwZCQkIQHx+PgIAArFixwpxhAQCUJXYQ1CLIPHXnQTp6qVFTqH8ovjJbjIIUKUrP2OP2j4sx6NVSXNzuhL8Xu2nr+N9ai/S1rii/IIGgAS7vkyL7d0fUFDQ9vG8t5B5qiCVAaZHu1I7SQgncfVRmiso05AolxGIBpSW6P9hKSqRw99A/n8LdoxYl19UvLZFCIhEgVygBAIcP+eKe+8/Av2MFRCIBA8LzMWToZXj8a50jbs9G9x4lWPtp31beK9OTyxuOW0mpo055SakjPNxrWm07j09LRfEVR6Qe9bt55XaA76fWoYEIGtgZsVjGULzZJs/V1dUhJSUFr7zyik55VFQU9u/fr7eNUqmEUqnUvi4vLzdpjAAguu7fURCApv5tBUEEkUjA8PeK4eDa0CtXv1KKXXM9MXhhKSQyAbcsKMVfr7ljc3QHQAS4BqjQ/d4qnN3obNodaUeE656QJBIBsJCnJjWXcN2bRYSbzKy97m/a998/5Ss/7o9nn0/BqjXbAYiQe9kZv23vgtFjLwAAvLyr8eScI3jtpeGor7fgH4uN3iNCq81Ivv+eNIwcfgEvLRhjcceI7yfj8Dp2EysqKoJarYavr+7Qjq+vL/Ly9J/3iouLw+LFi9siPEjdNRCJBdQU6b6Za4vFcPTSfzWjo7caTr5qbVIHAEW3ekAQoTpPDHkXFWQeGtyeUAy1ElCWiuHoo8bh9xRw6WQpV0i2XPkVMdQqwN1bt3eu8FKhpNC6LtAoL5NCrRbB3V23N+XmrmzU67qq5IqsUe9L4aaESiVCebmDdr3/fWMo7O3VkCvqUFwkw2MzjyM/r+GHYY+eJXB3V+KDlb9r1yEWCwgNK8KESecw8c57odG03y+n8vKrx023d+6mqEVJqczo9d83KR0P3X8CsQtHI/Oi/ol27RHfT9QcZv82FV3XJRYEoVHZVbGxsZg/f772dXl5OQICAkwSl9gB8OxTh8v7ZOg85tqXTO5+GQJG6R8S9BmoxMVtjqivEsHeuSG5l2dKILIT4NRBN3GLpYCTrxqaeiBrhyMCo1tvmLG9UtXb4cwxJwwcUYH9267NrB04ogJ/bbfcmbb6qFR2OHvaDQPC8/HXvo7a8gHh+Tiwz19vm4x0DwyOzNUpGxiRjzOn3aFW6541q68Xo7jIEWKxBsOG52DPrk4AgCOHffBUzBidus+9mIxL2a744bvgdv8lrFKJceacBwb0y8P+A5215QP65+HA352MWvf996ThPw+cwIJFd+DMWU9jQ21TfD+1DmMnwKmvH25sp8yW2L28vCAWixv1zgsKChr14q+SSqWQSttuklnIYxXY95InPEPr4D1AiTPrXVCVK0bPhyoBAIf/p0B1vhi3vnsFABB0VzWOJcixP9YD/eaWQVkiRsr/uaHbfVWQyBreEIVHHVCdL4ZHSB2q88U4+qECgkaE0BmmP63QHmxc7YUXP8jG6WOOyEh2xrhHiuHTsR5b11nWF60hfvqxJ55/5SDOnHbHyXRP3Dn+PLx9qpH4c1cAwKMxx+HpVYP/vXMLACDx526YMPEcZj51FNu2BqFX72JERWfi3TcHa9cZ3KsYnl61OH9OAU+vGjw8LR0iEfDjd8EAgJoae1y8oPsjqbZWjPJyh0bl7dXGzSF4cd5+nDnrgYxT3ogeewY+XlXYuq0HAOCxqanw9KzGe/HDtG26BjV8BmWOKigUtegadAUqlR2yst0ANCT1aQ8fxTv/uxX5BS5wd2v4IV1TK0FtrWXM8ub7yXgN59iNeAgMh+JvzMHBAeHh4UhKSsI999yjLU9KSsLEiRPNFZaOoHE1UJaU4liCHDUFYrj1rMeo1UVw6djQ+64pFKMq99pQvb2zgDGfF+LgUndsvc8XUjcNukTXoP+8Mm0dtVKEI/EKVGRLYO+kQcfbanHru8VwkFvGL0Fj7driDld3NR5+Lh8ePipcPCXDa48EoSDHMmYnN8funQFwlddhytQMeHjU4sIFORbG3oqCgoZhTnfPWp1rkPPznPHGq7fiidlHcdfd51BcLMOqj/pj355rPVV7Bw2mPX4CHfyqUFMjQfLfHfDe27egqsp6jt/uvV0gd1Xi4cnH4e5Rg4sX3fD6kttRUNhwmamHew18rrumPSE+Ufv/PbtfwR23XUB+vjOmP9Hw3TIh+jQc7DV4/ZXdOu2++rYvvvqun4n3qHXw/USGEgmC+cYW1q9fj6lTp2LlypWIjIzE6tWr8cknnyAtLQ2BgYE3bV9eXg6FQoFVh8Ph6GL2swrt2rpg05yysDbikB7mDsEiaFyMP99tC+wqbeeOki2lUivx+6llKCsrg1wuN8k2ruaKH472gpNryycBVleo8UC/kyaNtTWY9XK3yZMnIz4+HkuWLEH//v2xe/duJCYmGpTUiYiImsNcN6hpzo3YHn30UYhEokZLnz59DN6e2W+jM3v2bFy4cAFKpRIpKSkYMWKEuUMiIiIrZNw17A1LczX3RmzLly9Hbm6udsnOzoaHhwceeOABg7dp9sRORERkrZp7IzaFQoEOHTpol+TkZJSUlOCxxx4zeJs8MU1ERDZBLYigNuJGR1fbXn9ztKau2GrJjdiu99lnn2H06NHNOkXNHjsREdkENeyMXgAgICAACoVCu8TFxendXktuxPZvubm5+PXXXzFjxoxm7Sd77ERERM2QnZ2tMyv+ZvdXac6N2P5t7dq1cHNzw6RJk5oVHxM7ERHZBI1gB40Rd57T/HN1uFwuN+hyt5bciO0qQRDw+eefY+rUqXBwaN59BTgUT0RENqG1huIN9e8bsf1bUlIShg4desO2u3btwtmzZxETE9Ps/WSPnYiIyETmz5+PqVOnIiIiQnsjtqysLMyaNQtAwzNQcnJysG7dOp12n332GQYPHozQ0NBmb5OJnYiIbIIGMGpWvKYFbSZPnozi4mIsWbIEubm5CA0N1bkRW25ubqNr2svKyrBhwwYsX768RXEysRMRkU1o6U1m/t2+JWbPno3Zs2fr/dvatWsblSkUClRXVzeubCCeYyciIrIi7LETEZFNMP557JbRF2ZiJyIim8DnsRMREVkRW+mxW0aUREREZBD22ImIyCa05CYz17e3BEzsRERkEzSCCBpjrmM3om1bsoyfH0RERGQQ9tiJiMgmaIwcijfm5jZtiYmdiIhsgvFPd7OMxG4ZURIREZFB2GMnIiKboIYIaiNuMmNM27bExE5ERDaBQ/FERERkcdhjJyIim6CGccPp6tYLxaSY2ImIyCbYylA8EzsREdkEPgSGiIiILA577EREZBMEI5/HLvByNyIiovaDQ/FERERkcayix/7fv++CnaPM3GG0aw5LHcwdgkXw268ydwgWQZp4yNwhWARLuTzKnNRCfZtty1Ye22oViZ2IiOhm1EY+3c2Ytm3JMqIkIiIig7DHTkRENoFD8URERFZEAztojBioNqZtW7KMKImIiMgg7LETEZFNUAsiqI0YTjembVtiYiciIpvAc+xERERWRDDy6W4C7zxHREREbY09diIisglqiKA24kEuxrRtS0zsRERkEzSCcefJNUIrBmNCHIonIiKyIuyxExGRTdAYOXnOmLZtyTKiJCIiMpIGIqOXlkhISEBQUBBkMhnCw8OxZ8+eG9ZXKpVYsGABAgMDIZVK0a1bN3z++ecGb489diIiIhNZv3495s2bh4SEBAwbNgyrVq1CdHQ00tPT0blzZ71tHnzwQeTn5+Ozzz5D9+7dUVBQAJXK8EdKM7ETEZFNMMed55YtW4aYmBjMmDEDABAfH4/t27djxYoViIuLa1R/27Zt2LVrF86fPw8PDw8AQJcuXZq1TQ7FExGRTbh6jt2YpTnq6uqQkpKCqKgonfKoqCjs379fb5stW7YgIiIC7777Ljp27IiePXvihRdeQE1NjcHbZY+diIioGcrLy3VeS6VSSKXSRvWKioqgVqvh6+urU+7r64u8vDy96z5//jz27t0LmUyGn376CUVFRZg9ezauXLli8Hl29tiJiMgmaCDS3i++Rcs/k+cCAgKgUCi0i74h9X8TiXSH8AVBaFSmjVGjgUgkwtdff41bbrkF48aNw7Jly7B27VqDe+3ssRMRkU0QjJjZfrU9AGRnZ0Mul2vL9fXWAcDLywtisbhR77ygoKBRL/4qPz8/dOzYEQqFQlsWEhICQRBw6dIl9OjR46ZxssdOREQ2waje+r+eDCeXy3WWphK7g4MDwsPDkZSUpFOelJSEoUOH6m0zbNgwXL58GZWVldqy06dPw87ODp06dTJoP5nYiYiITGT+/Pn49NNP8fnnnyMjIwPPPfccsrKyMGvWLABAbGwspk2bpq0/ZcoUeHp64rHHHkN6ejp2796NF198EY8//jgcHR0N2iaH4omIyCaY485zkydPRnFxMZYsWYLc3FyEhoYiMTERgYGBAIDc3FxkZWVp67u4uCApKQnPPPMMIiIi4OnpiQcffBBLly41eJtM7EREZBP+PZze0vYtMXv2bMyePVvv39auXduorFevXo2G75uDQ/FERERWhD12IiKyCcbc7/1qe0vAxE5ERDbBXEPxbY1D8URERFaEPXYiIrIJttJjZ2InIiKbwMROAADFHwXw+DUf4tJ61HV0ROGUTqjp6XrTdrIzlQh4+xSUHR2RtaS3tly+twgdPrvYqP6Z1QMg2FvumZEpvU4gpu9ReDtW40ypO976exhS8v301g33zcULEQcQpCiFo0SFy5Wu+O5UCL5I66dTz9VBiefCD2JMYCYUDkpcqnTF2wcjsftSYFvskklMHJmOh8Yeg6dbDTIvu+Gj7yJx/EwHvXU9FNWY/eDf6BlYhE4+Zdj4ex98tD6yUb37R5/A3SMz4OtRibJKGXalBOGTDRGoU9nGx/uu6UV44KlCePjU4+JpGVa+4Y8TB13MHVa7w+NkO2zjk99CLn9fgc83l5A/tTNqezhDsbMIHZedxYU3+0Dl6dBkO7tqNTp8konqEDnE5fWN/q52tMOFuFCdMktO6tFBZxE7eD8W/zUch/M74KFe6fgkaivGb5yM3KrGP4Kq6+3xVUYoTl3xRI1KgnDfPCweuhs1Knt8f6rhR5C9nRprxv6C4lpHPPvHGORVucDPpRKV9fZtvXut5vZB5/D0QwcQ//VQHD/ri7tHnMS7z27D9DfuR8GVxl+wDhI1Sitk+Gprfzww5oTedY4efBZP3HcI76wZjrRzvujkW4ZXHt8NAPh4/RCT7k97cNvdJZi1+DI+erUj0g46Y/zUYiz9OhMzRwajMKfpz6it4XFqYCs9drNmk927d2PChAnw9/eHSCTCpk2bzBlOI+478lE2whPlt3mhzt8RhVMCUO/hALc/Cm/YzueLi6gY4oHa7s5N1BBBrbDXWSzZY6HHsOF0L/x4OgTnyxp663lVLvhPr3S99TOueGHr+R44W+qBnEo5tpzrib05AYjwzdXWua/HSSikSsz5bSwOF/jhcpUrUvL9cOqKV1vtVqt7YMwJJO7tia17eiEr1x0frY9EQYkzJo7M0Fs/r9gVH30XiR1/9UBVjf73SJ9uBTh+1he/H+yOvGJXJKd3wu8HuyI48MbvUWtx7xNF2P6tB7Z944nsszKsXNgRhZftcde0YnOH1q7wODUQcO2St5Ysgrl3wEBmTexVVVXo168fPvroI3OGoZ9KA9mFalT3kesUV/eRQ3ausolGgHxPERwKlCie6N9kHTulGkEvHEfQ/GPwjz8L6cXqVgu7rdnbqdHHsxB7LwfolO/L6YQBPvqfN3y9EI8iDPDJw8G8a8fsjs4XcKTAF28M3Yt9//kCP9+zHk+GHYadSNOq8bcViViN4MAiHErTfYjDobRO6NMtv8XrPX7GF8GBRegVVAAA8PMqx5C+2ThwvLNR8VoCib0GPcKqkbJLd1QoZZcrekdUmSmq9ofH6ZrWeghMe2fWofjo6GhER0ebM4QmiStUEGkAlVy3p6RWSCA50Xh4HQDs82rh9WMOsmODAbH+N0Cdnwx5MV2g7OQIca0abkkFCHjrJC4u7o36DrJW3w9Tc5fWQmInoLhG9+EERTVO8HbKvmHbXZO/hIesBmKRgI9SI/Dj6RDt3wJcKzDE7zJ+Pt8DT+wYh0B5Gd6I3AOJnQYfH4kwyb6YksKlFmKxgJJy3eNUUu4ID4Vhz1jW549D3aBwrcWHL/8CEQRIJAI2/RmCb37td/PGFk7uoYZYApQW6X6NlRZK4O6jMlNU7Q+Pk+2xqHPsSqUSSqVS+7q8vNz0G70+Pzc1FqMR4LcqE8WT/G+YoGu7uaC227XzqTXdXdB5UQbcfi9A4cOW28sSrjsuIpEA4Sa/bh/eOhFO9vXo552P5yP+xsUKObae76FtX1zriNf3jYBGsENasTd8nKoQ0/eoRSb2q/QdJ2PG9/oHX8bU8UcQ//VQpJ/3QUefcjzz0F8oLnPCl78MMC5YC9H4mMKoY2qteJxs5xy7RSX2uLg4LF68uE22pXaVQLADJGW6vXNxuQoqPefE7WrVkF2ohjQrCz5f/fOkHgEQCUCPmBRcer4HanrLG7WDnQjKIGc45Csb/80ClChlUGlE8HLS7XV6ympQVHPjRwxeqmw4HqdLPOHlWINnBiRrE3thtRNU1z2J6XyZO3ycqmFvp0a9RtzKe2JaZZUyqNWiRr1zN9daXCk37FGM+jw+MQU7/uqOrXt6AQAyczzgKK3H81P34qut/W/648qSlV8RQ60C3L11e50KLxVKCi3qq82keJyusZXEblFTsWNjY1FWVqZdsrNvPNRrFIkdars4wSmtQqfYKb1cp8d9lUYmxoX/9sbFxdeWspHeqOsgxcXFvVHbrYmJdIIAaVa13h8LlqBeI0ZasTeG+ev+Wwz1z0Fqgf7LuPQRoeF8/VWHCzqgs2uZznSVLvJSFFQ7WVxSBwCVWoxTF70Q0TtHpzyidw7Szvm2eL1SqarRl41aYweRCBY01adlVPV2OHPMCQNH6H5GB46oQHpyUxNXbQ+Pk+2xqJ9rUqkUUqm0zbZXEuULv08uoLaLE2q7O0Oxqwj2xXUovb1hZrbXDzmQlNYhb2YQYCdCXSfdnpdaLoHG3k6n3GPTZdR2c0a9rwx2/5xjl2ZXo2Cq5Q7DrzkRhndH/IETRT5ILfDF5OB0+LlU4LuTDZeuzQ//G77OVXh59x0AgCkhJ5Bb6YLzZW4AgHDfPDze9yi+Sr92CeC3J/tgau8TWDBkH75KD0WgvAxP9kvFl+mhjbZvKX5ICsWrMbtw6oIX0s77YMKIU/D1qMSWnQ297Zn3HoKXWxXiPh+pbdM9oGHWsqNUBYVrLboHFKNeZYeLue4AgL+OdsYDY07gbJYn0jN90NGnDDGTUrDvaGejnjttKTau9sKLH2Tj9DFHZCQ7Y9wjxfDpWI+t6zzNHVq7wuPUwFZ67BaV2Nta5WAPFFSp4LklF+KyhhvU5DzXHSqvhh8X4rJ6SIrrmrVOcY0avl9kQVxWD42jGMrOTsh+JRi1XS33l/Ovmd3hLq3F7P7J8HGqxukSDzyxYxwu/3MNu7dTFfycr/UW7CBgfsTf6ORSAbVgh6xyOf6XPFj7QwAA8qpc8Pi28YgdvB9bJv2A/GpnrEvri0+O92/r3Ws1fx7qBrmzEtMnpMJDUY3My+54eflY5F9pOE6eimr4eupecfHpwp+0/x/cpQhjhpxDXpELHnrlIQDAl78MgCCIEHNPCrzcqlBaIcP+o53x2U+WOw+hOXZtcYeruxoPP5cPDx8VLp6S4bVHglBgQ9dmG4LHqYEgiIw6PWUpp7ZEgnD9lIq2U1lZibNnzwIABgwYgGXLluH222+Hh4cHOne+eQ+2vLwcCoUCnVYshJ2j5c0ob0sONvYBbim//ZwlbAhp4iFzh0BWQiXUYyc2o6ysDHK5nnlIreBqrhi2+WlInFs+6quqUmLfxI9MGmtrMGuPPTk5Gbfffrv29fz58wEA06dPx9q1a80UFRERWSM+j70NjBw5EmYcMCAiIhtiK+fYrX92DRERkQ3h5DkiIrIJtjJ5jomdiIhsgq0MxTOxExGRTbCVHjvPsRMREVkR9tiJiMgmCEYOxVtKj52JnYiIbIKAxk+5a257S8CheCIiIivCHjsREdkEDUQQ8c5zRERE1oGz4omIiMjisMdOREQ2QSOIIOINaoiIiKyDIBg5K95CpsVzKJ6IiMiKsMdOREQ2wVYmzzGxExGRTWBiJyIisiK2MnmO59iJiIhMKCEhAUFBQZDJZAgPD8eePXuarLtz506IRKJGy8mTJw3eHnvsRERkE8wxK379+vWYN28eEhISMGzYMKxatQrR0dFIT09H586dm2x36tQpyOVy7Wtvb2+Dt8keOxER2YSGxC4yYmn+NpctW4aYmBjMmDEDISEhiI+PR0BAAFasWHHDdj4+PujQoYN2EYvFBm+TiZ2IiKgZysvLdRalUqm3Xl1dHVJSUhAVFaVTHhUVhf37999wGwMGDICfnx9GjRqFP//8s1nxMbETEZFNMK63fm1GfUBAABQKhXaJi4vTu72ioiKo1Wr4+vrqlPv6+iIvL09vGz8/P6xevRobNmzAxo0bERwcjFGjRmH37t0G7yfPsRMRkU0QYNwz1a+2zc7O1jn/LZVKb9hOJNKdTS8IQqOyq4KDgxEcHKx9HRkZiezsbLz33nsYMWKEQXGyx05ERNQMcrlcZ2kqsXt5eUEsFjfqnRcUFDTqxd/IkCFDcObMGYPrM7ETEZFNaK2heEM5ODggPDwcSUlJOuVJSUkYOnSowetJTU2Fn5+fwfU5FE9ERLahtcbim2H+/PmYOnUqIiIiEBkZidWrVyMrKwuzZs0CAMTGxiInJwfr1q0DAMTHx6NLly7o06cP6urq8NVXX2HDhg3YsGGDwdtkYiciIttg5C1l0YK2kydPRnFxMZYsWYLc3FyEhoYiMTERgYGBAIDc3FxkZWVp69fV1eGFF15ATk4OHB0d0adPH2zduhXjxo0zeJsiQbCUB9E1Vl5eDoVCgU4rFsLOUWbucNo1hxwHc4dgEfz2q8wdgkWQJh4ydwhkJVRCPXZiM8rKynQmpLWmq7mi69oFsHNqea7QVNfi/KNvmjTW1sAeOxER2QRbeR47EzsREdkEPt3NgnR/6ggkIntzh0FWYPvlI+YOwSKM9e9v7hAsQvU9g80dQrunqq8Fft5s7jCsilUkdiIiopsSRC2aAKfT3gIwsRMRkU2wlXPsvEENERGRFWGPnYiIbIMZblBjDgYl9g8++MDgFc6dO7fFwRAREZkKZ8X/y/vvv2/QykQiERM7ERGRGRmU2DMzM00dBxERkelZyHC6MVo8ea6urg6nTp2CSsVbcBIRUfvX1k93M5dmJ/bq6mrExMTAyckJffr00d68fu7cuXj77bdbPUAiIqJWIbTCYgGandhjY2Nx9OhR7Ny5EzLZtZvpjx49GuvXr2/V4IiIiKh5mn2526ZNm7B+/XoMGTIEItG1YYnevXvj3LlzrRocERFR6xH9sxjTvv1rdmIvLCyEj49Po/KqqiqdRE9ERNSu2Mh17M0eih80aBC2bt2qfX01mX/yySeIjIxsvciIiIio2ZrdY4+Li8Odd96J9PR0qFQqLF++HGlpafjrr7+wa9cuU8RIRERkPPbY9Rs6dCj27duH6upqdOvWDTt27ICvry/++usvhIeHmyJGIiIi4119upsxiwVo0b3i+/btiy+++KK1YyEiIiIjtSixq9Vq/PTTT8jIyIBIJEJISAgmTpwIiYTPlCEiovbJVh7b2uxMfOLECUycOBF5eXkIDg4GAJw+fRre3t7YsmUL+vbt2+pBEhERGY3n2PWbMWMG+vTpg0uXLuHw4cM4fPgwsrOzERYWhieeeMIUMRIREZGBmt1jP3r0KJKTk+Hu7q4tc3d3x5tvvolBgwa1anBEREStxtgJcBYyea7ZPfbg4GDk5+c3Ki8oKED37t1bJSgiIqLWJhKMXyyBQT328vJy7f+/9dZbmDt3LhYtWoQhQ4YAAA4cOIAlS5bgnXfeMU2URERExrKRc+wGJXY3Nzed28UKgoAHH3xQWyb8M1VwwoQJUKvVJgiTiIiIDGFQYv/zzz9NHQcREZFp2cg5doMS+2233WbqOIiIiEyLQ/E3Vl1djaysLNTV1emUh4WFGR0UERERtUyLHtv62GOP4ddff9X7d55jJyKidslGeuzNvtxt3rx5KCkpwYEDB+Do6Iht27bhiy++QI8ePbBlyxZTxEhERGQ8oRUWC9DsHvsff/yBzZs3Y9CgQbCzs0NgYCDGjBkDuVyOuLg4jB8/3hRxEhERkQGa3WOvqqqCj48PAMDDwwOFhYUAGp74dvjw4daNjoiIqLXwsa36BQcH49SpU+jSpQv69++PVatWoUuXLli5ciX8/PxMEaNFuWt6ER54qhAePvW4eFqGlW/448RBF3OH1a7wGOn6ea0nfljhgysF9gjsWYtZS3LQd3BVk/X/2OiO7xN8cPm8FM5yNcJHluOJNy5D7mGb81v4ftI1aXga/jP6GDwV1biQ644PfozEsXP6v5tH9MvEpOHp6NGpGPYSNTJz3bEmMRwHMwLaOOq2Yezd4yzlznMtOseem5sLAFi4cCG2bduGzp0744MPPsBbb73V6gFaktvuLsGsxZfx7Qc+mB3VEyf+dsbSrzPh3bHu5o1tBI+Rrp2b3bByYUf8Z24+EnacQujgKrz2cFcUXLLXW//E3874v7mdcedDxVi98yQWrLqA00ed8P4L1vlFfDN8P+m6Y+A5zL3/L3y5fQBi4u7F0bMd8H9zfoWPe6Xe+v265yL5ZEe8mHAnZrxzL1LP+OPtWdvRo1NRG0dOranZif3hhx/Go48+CgAYMGAALly4gEOHDiE7OxuTJ09u1rri4uIwaNAguLq6wsfHB5MmTcKpU6eaG1K7ce8TRdj+rQe2feOJ7LMyrFzYEYWX7XHXtGJzh9Zu8Bjp2rjaG2P/cwXRD19B5x5KPLUkB97+9fhlnZfe+hmHneAbUIdJM4rQoXMdQgdXYfwjxTh91KmNI28f+H7SNXnUMWz9Kxi/7O+Fi/nu+HDDUBSUuOCe4el663+4YSi++a0/Tmb54FKhAqu33IJLhQoM63uxjSNvI2aaPJeQkICgoCDIZDKEh4djz549BrXbt28fJBIJ+vfv36ztNTuxX8/JyQkDBw6El5f+L6Ib2bVrF+bMmYMDBw4gKSkJKpUKUVFRqKpqehiyvZLYa9AjrBopu1x1ylN2uaJ3hOXtjynwGOmqrxPhzDEnhN9WoVMeflsF0pOd9bbpHVGFolx7HPzdFYIAlBRKsGerG24ZXa63vjXj+0mXRKxGz4AiHMzopFN+KKMTQrs2fnCXPiKRACdpHcqrpaYI0SatX78e8+bNw4IFC5Camorhw4cjOjoaWVlZN2xXVlaGadOmYdSoUc3epkHn2OfPn2/wCpctW2Zw3W3btum8XrNmDXx8fJCSkoIRI0YYvJ72QO6hhlgClBbpHtLSQgncfVRmiqp94THSVX5FDI1aBDevep1yN+96lBS46m3TZ1A1Xv7oIt6a1QV1SjuoVSIMiSrDnKWX2iLkdoXvJ10Kl1pIxAJKyh11yksqHOEhrzZoHQ+NOgaZgwp/pHQzRYhmJ4KR59hb0GbZsmWIiYnBjBkzAADx8fHYvn07VqxYgbi4uCbbPfnkk5gyZQrEYjE2bdrUrG0alNhTU1MNWtm/HxTTEmVlZQAaZtvro1QqoVQqta///dS59kK47k0jEsFirn1sKzxGuq7/2AiCqMlvkIunpUh4vRMefi4P4SMrcKXAHp/+1x8fvByA+cuyTR9sO8T3ky6h0ZtHaHSM9BkVfhaPjUtB7KoolFY63ryBDbs+90ilUkiljUc56urqkJKSgldeeUWnPCoqCvv3729y/WvWrMG5c+fw1VdfYenSpc2Or908BEYQBMyfPx+33norQkND9daJi4vD4sWLTR5LS5RfEUOtAty9dXsKCi8VSgpbfOdeq8JjpEvuoYadWEBJoe5EubIiSaNjdNX6D33RZ1AVHpjdcJlp1961kDlewvP39MD0l3Ph6Ws7PVW+n3SVVcqgUosa9c7dXWtRUnHjORh3DDyHVx7ZhTc+HYOUU51uWNeitdJDYAICdCerLly4EIsWLWpUvaioCGq1Gr6+vjrlvr6+yMvL07uJM2fO4JVXXsGePXsgkbTsfWz0OfbW8vTTT+PYsWP49ttvm6wTGxuLsrIy7ZKd3X56KKp6O5w55oSBI3TPlw4c0fT5UlvDY6TL3kFAj7BqHN6tO+x+eHfT54hra+wgum4s0U78z2sb66Xy/aRLpRbjdLYXBvXK0Skf1OsSTpz3baJVQ0/91ak7sWTNKPyV1tnUYZpXK02ey87O1slFsbGxN9zs9aPZgiDoHeFWq9WYMmUKFi9ejJ49e7Z4N9vFz9pnnnkGW7Zswe7du9GpU9O/Fpsa7mgvNq72wosfZOP0MUdkJDtj3CPF8OlYj63rPM0dWrvBY6Tr3icK8X9zO6NnWDVCIqqQ+JUnCnLsMX5aw+VGn7/lh6I8e7z0QcNEmyFjyhH/YgB+/qISESMrcCXfHisXdkTwgCp4drCd3vpVfD/pWv97GF6b/idOZnkh7bwv7r41Az4eldi0NwQA8OTdB+HlVoU3190OoCGpvzb9Tyz/YSjSLvhoe/vKOgmqah3Mth/tnVwuh1wuv2k9Ly8viMXiRr3zgoKCRr14AKioqEBycjJSU1Px9NNPAwA0Gg0EQYBEIsGOHTtwxx133HS7Zk3sgiDgmWeewU8//YSdO3ciKCjInOEYbdcWd7i6q/Hwc/nw8FHh4ikZXnskCAU5/IBcxWOka+TEUlSUiPH1+x1wpUCCwOBaLP3qPHw7NUyou1Jgj8J/HZuoyVdQU2mHLWu88MnijnBWqNF/WAViFuSaaxfMiu8nXX8c7ga5cy0ejT4MT3k1MnM98FJCNPKvNIwKeSqq4fuva9on3poBiVjA8w/tw/MP7dOW/3qgJ976cmRbh296bfwQGAcHB4SHhyMpKQn33HOPtjwpKQkTJ05sVF8ul+P48eM6ZQkJCfjjjz/w448/GpwjRYJgyLQK05g9eza++eYbbN68GcHBwdpyhUIBR8ebT94oLy+HQqHASEyERKT/hh5EzbH98hFzh2ARxvr3N3cIFqH6nsHmDqHdU9XX4uDPr6OsrMygXnBLXM0VXd58E3YyWYvXo6mtxYUFC5oV6/r16zF16lSsXLkSkZGRWL16NT755BOkpaUhMDAQsbGxyMnJwbp16/S2X7RoETZt2oQjR44YHKdZe+wrVqwAAIwcOVKnfM2aNdqb4BAREVmqyZMno7i4GEuWLEFubi5CQ0ORmJiIwMBAAEBubu5Nr2lvrhZNnvvyyy8xbNgw+Pv74+LFhjsUxcfHY/Pmzc1ajyAIehcmdSIianVmuvPc7NmzceHCBSiVykb3aVm7di127tzZZNtFixY1q7cOtCCxr1ixAvPnz8e4ceNQWloKtbrhwRNubm6Ij49v7uqIiIjaho08j73Zif3DDz/EJ598ggULFkAsFmvLIyIiGp30JyIiorbV7HPsmZmZGDBgQKNyqVRqkfd4JyIi28DHtjYhKChI73j/r7/+it69e7dGTERERK3v6p3njFksQLN77C+++CLmzJmD2tpaCIKAgwcP4ttvv0VcXBw+/fRTU8RIRERkvDa+jt1cmp3YH3vsMahUKrz00kuorq7GlClT0LFjRyxfvhwPPfSQKWIkIiIiA7XoOvaZM2di5syZKCoqgkajgY+PT2vHRURE1Kps5Ry7UTeo8fLyaq04iIiITItD8foFBQXd8Lnr58+fNyogIiIiarlmJ/Z58+bpvK6vr0dqaiq2bduGF198sbXiIiIial1GDsVbbY/92Wef1Vv+8ccfIzk52eiAiIiITMJGhuJbdK94faKjo7Fhw4bWWh0RERG1QKs93e3HH3+Eh4dHa62OiIioddlIj73ZiX3AgAE6k+cEQUBeXh4KCwuRkJDQqsERERG1Fl7u1oRJkybpvLazs4O3tzdGjhyJXr16tVZcRERE1ALNSuwqlQpdunTB2LFj0aFDB1PFRERERC3UrMlzEokETz31FJRKpaniISIiMg0+j12/wYMHIzU11RSxEBERmczVc+zGLJag2efYZ8+ejeeffx6XLl1CeHg4nJ2ddf4eFhbWasERERFR8xic2B9//HHEx8dj8uTJAIC5c+dq/yYSiSAIAkQiEdRqdetHSURE1BospNdtDIMT+xdffIG3334bmZmZpoyHiIjINHgduy5BaNijwMBAkwVDRERExmnWOfYbPdWNiIioPeMNavTo2bPnTZP7lStXjAqIiIjIJDgU39jixYuhUChMFQsREREZqVmJ/aGHHoKPj4+pYiEiIjIZDsVfh+fXiYjIotnIULzBd567OiueiIiI2i+De+wajcaUcRAREZmWjfTYm31LWSIiIkvEc+wW5D+HL8HRxSp2xWTWBQeYOwSLMP6W8eYOwSKUPNrZ3CFYBPe1f5k7hHZPJdS33cZspMfe7Ke7ERERUfvFbi4REdkGG+mxM7ETEZFNsJVz7ByKJyIisiJM7EREZBuEVlhaICEhAUFBQZDJZAgPD8eePXuarLt3714MGzYMnp6ecHR0RK9evfD+++83a3sciiciIptgjqH49evXY968eUhISMCwYcOwatUqREdHIz09HZ07N766xNnZGU8//TTCwsLg7OyMvXv34sknn4SzszOeeOIJg7bJHjsREZGJLFu2DDExMZgxYwZCQkIQHx+PgIAArFixQm/9AQMG4D//+Q/69OmDLl264JFHHsHYsWNv2Mu/HhM7ERHZhlYaii8vL9dZlEql3s3V1dUhJSUFUVFROuVRUVHYv3+/QSGnpqZi//79uO222wzeTSZ2IiKyDa2U2AMCAqBQKLRLXFyc3s0VFRVBrVbD19dXp9zX1xd5eXk3DLVTp06QSqWIiIjAnDlzMGPGDIN3k+fYiYiImiE7OxtyuVz7WiqV3rD+9U9HFQThpk9M3bNnDyorK3HgwAG88sor6N69O/7zn/8YFB8TOxER2QTRP4sx7QFALpfrJPameHl5QSwWN+qdFxQUNOrFXy8oKAgA0LdvX+Tn52PRokUGJ3YOxRMRkW1o48vdHBwcEB4ejqSkJJ3ypKQkDB061PCwBaHJ8/j6sMdOREQ2wRyXu82fPx9Tp05FREQEIiMjsXr1amRlZWHWrFkAgNjYWOTk5GDdunUAgI8//hidO3dGr169ADRc1/7ee+/hmWeeMXibTOxEREQmMnnyZBQXF2PJkiXIzc1FaGgoEhMTERgYCADIzc1FVlaWtr5Go0FsbCwyMzMhkUjQrVs3vP3223jyyScN3iYTOxER2QYzPQRm9uzZmD17tt6/rV27Vuf1M88806zeuT5M7EREZDss5EEuxuDkOSIiIivCHjsREdkEW3lsKxM7ERHZBjOdY29rHIonIiKyIuyxExGRTeBQPBERkTXhUDwRERFZGvbYiYjIJnAonoiIyJrYyFA8EzsREdkGG0nsPMdORERkRdhjJyIim8Bz7ERERNaEQ/FERERkadhjv4mTX7sg/TNXVBeK4dajHoNeLYFvRF2T9dV1wLGPFTi/xQk1hWI4dVCj76xy9Li/CgCgqQeOr5Lj3CZnVOeLoQiqx8AXytBxRG1b7ZLZ3TW9CA88VQgPn3pcPC3Dyjf8ceKgi7nDMonx913EvVPPw8NTiazzLlj9fm+kHfFosn7ogGLMnJeBzl0rcaVIih+/7IpfNwbq1HF2qce0p05h6O35cHGtR/5lR3y6PATJ+30AAA9MP4uht+ejU2Al6pRiZBx3x5oPg5GTZTnH+L7BJzB1+FF4ulbjfIE73t86DEcu+OmtO7LPedx3Sxp6+hfDXqxGZoEHPvk9AgfOBGjrjB94Egvv39mo7a1vzECdyja+Bm3pc9cUkSBAJLS8221M27ZkG+/oFspMdERynBsGLyyB90Alznzngt9neuPurXlw8VfrbbPrWS/UFtsh8s0rkHdWofaKGBrVtb+nxjck/cilJVB0rcflPTLsfNoTd35XAM/e9W20Z+Zz290lmLX4Mj56tSPSDjpj/NRiLP06EzNHBqMwx8Hc4bWq4aMvY+b8dCS8G4qMo+64854sLI4/hKcmj0BhvmOj+r7+1Vgcn4xtmwLw3sL+COlXgtkvnUBZiQP2/9mQ1CQSDZZ+dBBlVxzw1isDUFTgCG/fGtRUX/so9x14BVt/CMTpDAXEYgHTnjqFpR8exKzJI6Csbf8f+dF9z2L++P14d8twHL3YAffcko746VsxOX4y8stcG9Uf0CUXB892QsKOwaisdcBd4afwv6m/4rEV9+J0rpe2XmWtAx5Y9pBOW1tJ6rb0ubshDsWb3ooVKxAWFga5XA65XI7IyEj8+uuv5gxJR8YaV3S/rwo9HqiCWzcVBi0ohXMHNU5/q/9Xbs5uGfIPSTFqdRH8hyrh0kkNr7A6+Ay81sM/v9kZfWdVoNNttXANUCN4ShX8b61F+ueNv7Cs0b1PFGH7tx7Y9o0nss/KsHJhRxRetsdd04rNHVqru2dKJnZsCcCOzQHIvuCCT97vjaJ8Gcbdd1Fv/XH3ZqEwT4ZP3u+N7Asu2LE5AEk/d8K9j2Rq64y5Oxuu8nr898VwZBzzQGGeI9KPeiDzjFxb541nb8FvWzsh67wrMs/I8f6SMPj41aJ7SLnJ97k1TLn1GLak9MLm5BBcKGzoreeXueC+wel667+/dRi+3DMAGTk+yC52w4odg5FdrMDwkAs69QQBKK500llshS197sjMPfZOnTrh7bffRvfu3QEAX3zxBSZOnIjU1FT06dPHnKFBXQcUpzkg9IkKnXK/YbUoTNX/Czf7D0d4htbhxKeuOL/ZCRInAQF31KD/s+WQyBp+6qnrAbGD7s8+sUxAwWGpaXakHZHYa9AjrBrrP/LRKU/Z5YreEVVmiso0JBINuvcqxw/ruumUH/7bGyFhpXrb9OpbgsN/e+vWP+CNqLsvQSzWQK22w+DhBTh53A2zX0rD4BH5KCt1wK7t/vhxXTdoNCK963V2aRgyqiyzN37HTEwiVqOXfyHW7RqgU/732U4IC8wzaB0ikQAnaT3Kq2U65Y4O9dj84lewsxNwJtcTK5Nu0enRWytb+tzdjK3Mijdrj33ChAkYN24cevbsiZ49e+LNN9+Ei4sLDhw4YM6wAADKEjsIahFknrpD7o5eatQUivW2qcwWoyBFitIz9rj942IMerUUF7c74e/Fbto6/rfWIn2tK8ovSCBogMv7pMj+3RE1BfrXaU3kHmqIJUBpke7vydJCCdx9VE20skxytzqIJQJKi3V/sJVecYC7p1JvG3dPJUqv6P5oLC2WQiIRIHdrGPXp0LEaw+7Ig51YwKLnBmH9591xz8OZmPzY2SYiETBzXgZOHHHHxfPtf1TIzakWErGA4krdUxVXKpzg6VJt0DoevvUoHB3q8dvxaz+qLha6Y8mG2/HCl3fi9fWjoVRJ8OmTmxDgWdqa4bdLtvS5uymhFRYL0G5OMKnVavzwww+oqqpCZGSk3jpKpRJK5bUvxfJy0w8tiq7rBAkCAP0dIwiCCCKRgOHvFcPB9Z8e+iul2DXXE4MXlkIiE3DLglL89Zo7Nkd3AESAa4AK3e+twtmNzqbdkXbk+vknIhEs5gPTXNfvlkjUeP916jdqcLWg4U1nZyegtMQBH77VFxqNCGdPKuDhXYv7HsnEt5/1aLS+p15MQ5fuFXjxiSEt3gezaPQeESA09cH7l6iwM5g5KhkvfHknSqqu/Tg4ke2LE9m+2tdHL3bAl3N+xIORJ/C/X25ttbDbM1v63Nk6syf248ePIzIyErW1tXBxccFPP/2E3r17660bFxeHxYsXt0lcUncNRGIBNUW6PenaYjEcvfRPnHP0VsPJV61N6gCg6FYPCCJU54kh76KCzEOD2xOKoVYCylIxHH3UOPyeAi6d9K/TmpRfEUOtAty9dXsJCi8VSgrN/lZsVeWlDlCrRI165wr3OpRe0X/apaRYCndP3Ssu3DzqoFKJUF7aMIx+pUgGtUqkM+yenekCDy8lJBINVKprg3CzXkjD4BEFePnJISguaDxZrz0qrZZBpRbB07VGp9zdpQZXKm+8D6P7nsVr9+5C7LdjcOhcpxvWFQQR0nO8EeBZZnTM7Z0tfe5uhkPxbSQ4OBhHjhzBgQMH8NRTT2H69OlIT9c/SSY2NhZlZWXaJTs722RxiR0Azz51uLxP9zxd7n4ZvAfov9zNZ6AS1QVi1Fdd+9Itz5RAZCfAqYNu4hZLASdfNQQVkLXDEQGjaq5fndVR1dvhzDEnDByhO29h4IgKpCdb14iFSmWHsyflGHBLkU75gFuKkHHMTW+bk8fdG9cfXIQzGQqo1Q0f1fSj7vDrVA3Rv75hOnauQnGh9F9JXcCsF9IQOTIPr84ejPzLljNJTKUW4+Rlb9zSXfezfUv3HBy72KHJdlFhZ/DG/X/i9fWjsO9UYJP1rhHQ068YRRWWc2xaypY+dzdlI0PxZk/sDg4O6N69OyIiIhAXF4d+/fph+fLleutKpVLtDPqriymFPFaBsz8648yPzig9J8Ght9xQlStGz4cqAQCH/6fA3peuXZMcdFc1pG4a7I/1QOlZCfIPSZHyf27odl+VdvJc4VEHXNzhiIpsMfKTHfDbDG8IGhFCZ1jGjGVjbVzthTunXEHUQ8UI6F6LJxflwKdjPbau8zR3aK3up2+CEDUxG2MmZCOgSyVmPpcO7w41SPznuvTps09i/qKj2vqJGzvDx68GM+alI6BLJcZMyEbU3dnY+FXQtTobOsNVUYcnn0+Hf+dKDBpWgAcfPYetP15LZrNfSsPt0Tn4v9f7o6ZaAndPJdw9lXCQWsao0Dd7wzAx4iQmhJ9EF+8SPDduHzooKrDxYMNI3uyov7Ho/j+09aPCzmDRA39ieWIkTmT7wtOlGp4u1XCWXhstmXFHMob0yIa/ezl6+BXhtXt3oqdfsXad1s6WPnc3crXHbsxiCdrdOIwgCDrn0c0paFwNlCWlOJYgR02BGG496zFqdRFcOjZ8QdYUilGVe22o3t5ZwJjPC3FwqTu23ucLqZsGXaJr0H/eteE+tVKEI/EKVGRLYO+kQcfbanHru8VwkFvIO8ZIu7a4w9VdjYefy4eHjwoXT8nw2iNBKLDCa2n3/OYPuaIe/4k5Cw8vJS6ec8HC5wahMK9hSNnDSwlv32sjNfmXnbBwXgRmPpeBu+7PQnGRFKv+11t7DTsAFBU44vW5t2DmvAx8/PVeFBfKsGV9F/z4r9n34+/PAgC8s+pvnXjeXxyG37beeIi6PfjteHconGoRc0cyvFyrcS7fA899MQ55pQ2T/7xcq+Drdq33ec8t6ZCINXh54l68PHGvtvyXlJ5YsuEOAICrTInYSbvg6VqNyloHnL7shSdX3430S76wBbb0uSNAJAjmu5XOq6++iujoaAQEBKCiogLfffcd3n77bWzbtg1jxoy5afvy8nIoFAqsOhwOR5d29xulXVkXHHDzSgRJp47mDsEiFI7ubO4QLIL72r/MHUK7pxLqsRObUVZWZrJR2Ku5IvzBNyF2kN28QRPUdbVI+X6BSWNtDWbNhvn5+Zg6dSpyc3OhUCgQFhZmcFInIiJqLksZTjeGWRP7Z599Zs7NExERWR2OXxMRkW0QhBvfSMKQ9haAiZ2IiGwCr2MnIiIii8MeOxER2QYbeWwrEzsREdkEkaZhMaa9JeBQPBERkRVhj52IiGyDjQzFs8dOREQ2wVz3ik9ISEBQUBBkMhnCw8OxZ8+eJutu3LgRY8aMgbe3N+RyOSIjI7F9+/ZmbY+JnYiIbMPV69iNWZpp/fr1mDdvHhYsWIDU1FQMHz4c0dHRyMrK0lt/9+7dGDNmDBITE5GSkoLbb78dEyZMQGpqqsHbZGInIiIykWXLliEmJgYzZsxASEgI4uPjERAQgBUrVuitHx8fj5deegmDBg1Cjx498NZbb6FHjx74+eefDd4mEzsREdmE1hqKLy8v11maeiJpXV0dUlJSEBUVpVMeFRWF/fv3GxSzRqNBRUUFPDw8bl75H0zsRERkG4RWWAAEBARAoVBol7i4OL2bKyoqglqthq+v7uOBfX19kZeXZ1DI//vf/1BVVYUHH3zQ4N3krHgiIqJmyM7O1nlsq1QqvWF9kUik81oQhEZl+nz77bdYtGgRNm/eDB8fH4PjY2InIiKb0Fr3ipfL5QY9j93LywtisbhR77ygoKBRL/5669evR0xMDH744QeMHj26WXFyKJ6IiGxDG8+Kd3BwQHh4OJKSknTKk5KSMHTo0Cbbffvtt3j00UfxzTffYPz48c3eTfbYiYiITGT+/PmYOnUqIiIiEBkZidWrVyMrKwuzZs0CAMTGxiInJwfr1q0D0JDUp02bhuXLl2PIkCHa3r6joyMUCoVB22RiJyIim2COx7ZOnjwZxcXFWLJkCXJzcxEaGorExEQEBgYCAHJzc3WuaV+1ahVUKhXmzJmDOXPmaMunT5+OtWvXGrRNJnYiIrINZrql7OzZszF79my9f7s+We/cubNlG/kXnmMnIiKyIuyxExGRTTDHULw5MLETEZFt0AgNizHtLQATOxER2QY+tpWIiIgsDXvsRERkE0Qw8hx7q0ViWkzsRERkG1r4THWd9haAQ/FERERWhD12IiKyCbzcjYiIyJpwVjwRERFZGvbYiYjIJogEASIjJsAZ07YtWUViX7buPoilMnOH0a75Y7+5Q7AIqks55g7BIqhknc0dgkU4s3yIuUNo9zQ1tcDLm9toY/8sxrS3AByKJyIisiJW0WMnIiK6GQ7FExERWRMbmRXPxE5ERLaBd54jIiIiS8MeOxER2QTeeY6IiMiacCieiIiILA177EREZBNEmobFmPaWgImdiIhsA4fiiYiIyNKwx05ERLaBN6ghIiKyHrZyS1kOxRMREVkR9tiJiMg22MjkOSZ2IiKyDQKMe6a6ZeR1JnYiIrINPMdOREREFoc9diIisg0CjDzH3mqRmBQTOxER2QYbmTzHoXgiIiIrwh47ERHZBg0AkZHtLQB77EREZBOuzoo3ZmmJhIQEBAUFQSaTITw8HHv27Gmybm5uLqZMmYLg4GDY2dlh3rx5zd4eEzsREZGJrF+/HvPmzcOCBQuQmpqK4cOHIzo6GllZWXrrK5VKeHt7Y8GCBejXr1+LtsnETkREtuHq5DljlmZatmwZYmJiMGPGDISEhCA+Ph4BAQFYsWKF3vpdunTB8uXLMW3aNCgUihbtJhM7ERHZhjZO7HV1dUhJSUFUVJROeVRUFPbv39+ae6aDk+eIiIiaoby8XOe1VCqFVCptVK+oqAhqtRq+vr465b6+vsjLyzNZfOyxExGRbWilHntAQAAUCoV2iYuLu+FmRSLdqfiCIDQqa03ssRMRkW1opcvdsrOzIZfLtcX6eusA4OXlBbFY3Kh3XlBQ0KgX35rYYyciIpvQWpe7yeVynaWpxO7g4IDw8HAkJSXplCclJWHo0KEm20/22G9ictgJPBp+BN7O1ThX7I53dg3D4cv+eusO8M/Fc7ceQJB7CWT2KuSWu+KH473xZeq1SxbuC03HhJBT6OF5BQCQXuCN5fsG40S+6X69tTd3TS/CA08VwsOnHhdPy7DyDX+cOOhi7rDaHVs+Tg9EnMC0yKPwcq3G+QJ3vLdjGFKz/PTWvaPXedwfkYZg32LYS9Q4X+iBVbsi8Ne5AG2d1dM2I6JLbqO2e850xrPfjjPZfpiaYk8e3P/Ihbi8DnUdnFB4byBqu8lv2k52vgKdPkxDnZ8Tsl4K05Y75FbDM/ESpJcqYX+lDoX3BKJ0pP7jToaZP38+pk6dioiICERGRmL16tXIysrCrFmzAACxsbHIycnBunXrtG2OHDkCAKisrERhYSGOHDkCBwcH9O7d26BtMrHfwNieZ/Hybfuw9I/hSL3shwfC0rBi0lZM/PIh5FW4NqpfUy/Bt0dDcbrQEzUqCQb65+H1UbtQU2+PH080/IMM6nQZv57qgbjcDqhTifFYxBGsuvcX3LNuMgqqrP9L+7a7SzBr8WV89GpHpB10xvipxVj6dSZmjgxGYY6DucNrN2z5OEX1PosXxu5HXOJwHM3ugPsGpuPDKVtxf8Jk5JU3/twN7JyLv893wkd/DEZFrQMm9j+F+Id+xbTP7sWpPC8AwAvfj4W9+NptwxROtfjuyR/wW3rXNtuv1uZyuAjeP11EwQNBqAlyhWJ/PjquPImLsf2g8tDfgwQAuxoVfL86i+qeCkgq6nX+JqrToN5LiooBHvD+6aKpd6HtmeFe8ZMnT0ZxcTGWLFmC3NxchIaGIjExEYGBgQAabkhz/TXtAwYM0P5/SkoKvvnmGwQGBuLChQsGbbPdDMXHxcVBJBK16C47pjJt4FFsTOuFjWm9kVnijnd33Yq8ShdMDkvTW/9koTd+PdUD56544HK5HL+c7In9FwMwsOO1nsIr20Zj/bFQnCr0QmaJOxb9dhvsIGBw55y22i2zuveJImz/1gPbvvFE9lkZVi7siMLL9rhrWrG5Q2tXbPk4PRx5DJtSe2FTaggyixp66/llLrg/Il1v/fd2DMMX+wcg/bIPsq+44aM/BiOrWIERPS9o65TXylBc5aRdhnS9hNp6CZLSu7XRXrU+9525KBvijfJIH9R3cETRvV2gcneAYl/+Ddv5rM9ERbgXars07kgoA11QNDEQlQO9IEhMN7nLbDSC8UsLzJ49GxcuXIBSqURKSgpGjBih/dvatWuxc+dOnfqCIDRaDE3qQDtJ7IcOHcLq1asRFhZ288ptRGKnRm+fQuy/GKBTvv9iAPr7GXaZQi/vQvT3y0PypaaHsmQSFSRiDcpqm/6FbS0k9hr0CKtGyi7dXlfKLlf0jqgyU1Ttjy0fJ4mdGiF+hThwTvdz99f5TugXYNjnTgQBTtJ6lNfImqwzsf9J7DjRHbX19kbFazYqDaTZVagOdtMprgp2gyyzoslm8gMFsC+qxZU7O5k4QDInsw/FV1ZW4uGHH8Ynn3yCpUuXmjscLXfHWkjsBBRXO+mUF1c7wtOp+oZtf4tZB3fHGojtBKw4EIGNaU2fF3nu1gMoqHTGgSzr/6DJPdQQS4DSIt23XWmhBO4+KjNF1f7Y8nFyc/rnc1flqFN+pcoJns7ZBq1jauRRONrXY0ea/t54H/989PC9giU/32Z0vOYirlJBpAHUct0fJmpX+0bD61fZF9TA8+dsXHq2NyC2wt64IWzksa1mT+xz5szB+PHjMXr06JsmdqVSCaVSqX19/U0C2oLoX/9tyvQfJsHJvh5hfvmYN+wAssoU+PVUj0b1HgtPRXTwWTz+40TUqc3+T9Fmrv9siEQALOPz0qZ4nK4RQYBgwHVKY/ucwZO3JeO59XeipNpRb51JA07iTL4H0i7bzoRVaAR0WHcWV6I7od5H/3GxDUYmdgv5AJo1m3z33XdISUlBcnKyQfXj4uKwePFiE0fVoKRGBpVG1Kh37uFUg+ImvjCuyilvmJV6ptgTnk41eGrwoUaJffrAI5hxy2HM3DABp4s8Wzf4dqr8ihhqFeDurdvrVHipUFJoOz9sbsaWj1Np9T+fO+canXJ35xpcqbrx5y6q91m8cfcuvPzjGBzM1D8CJpPUI6rPOazcGdFqMZuD2lkCwQ4Ql+v2zsUV9VC5Nj69YFerhiy7CtKcTHhvyGwoFACRAHR/7gByngpBTc+W3Zec2h+znWPPzs7Gs88+i6+//hoyWdPnwv4tNjYWZWVl2iU727ChuZZQacRIL/BGZOdLOuWRnS/hSG4Hg9cjggAHie5DfB8NT8WTg1Pw1E/jkV7g0yrxWgJVvR3OHHPCwBG65wAHjqhAerKzmaJqf2z5OKk0YmTkemNwV93P9pCuOTia3fTnbmyfM1g08U8s2DgKe88ENllvTJ9zcJCokXi8Z6vFbBYSOygDnOF0qkyn2OlUGWqDGl85oJGJcfHlMGS9eG0pG+qLOh8Zsl4MQ22g9V+RA8AsD4ExB7P9/E9JSUFBQQHCw8O1ZWq1Grt378ZHH30EpVIJsVis06ap+/GayrrD/RA39nek5XvjaG4HPNA3HX6uFfj+WB8AwLPDDsDHuQoLdowCADwUdgK5FS7ILHEDAAz0z8P08KP49kiodp2Phafi6ciDeHnbaOSUy7UjAtX19qix1Ik8zbBxtRde/CAbp485IiPZGeMeKYZPx3psXWcboxaGsuXj9PVfYfjvPX8gI9cHxy754t6B6eigqMCGlIa5Kk/f8Td8XKvwxuY7ADQk9SWT/sR724fi+CVfeDo3fKaUKjEqlbrfF5MGnMTOk11QdoOJdZaiZKQfOnx1DsrOzqjp0nC5m32JEmXDGk4xeP6cBUlZHfIf6Q7YiVDnrztfSO0qgWBvp1uu0sAhr2G0RKQSICmrg8OlKghSMeq9Lf+YNcxqNyI5t3BWfFszW2IfNWoUjh8/rlP22GOPoVevXnj55ZcbJXVz2H66O9xktZg1JAXeTlU4W+yB2ZvHI/efa9i9navhJ6/U1rcTCXh22AF0VFRArbFDdpkc8fsG44d/fggAwOR+aXCQaPD+XTt0tpVwIAIrDgxqmx0zo11b3OHqrsbDz+XDw0eFi6dkeO2RIBRY+bXZzWXLx2lHenconGoxc0QyvFyqca7AA3O/GYfcsobPnZdLFTooro1m3BeeDnuxBrHj9iJ23F5t+ZYjPbFoyx3a1509SjGgcx6e+mp82+2MCVUO9EJhlQoe2y9BXFaPOj8n5DzZS3sNu6S8DpIS5U3WoktSVofA/7v2vez+Ry7c/8hFdXdX5DzT5wYtqT0RCUL7GVsYOXIk+vfvj/j4eIPql5eXQ6FQIHjeWxBLreDXpAn5v2u6RwSS7SmcFWnuECxCaUi7+XpttzQ1tch++TWUlZXp3H+9NV3NFaM7z4bEruWjviqNEr9lJZg01tZg3TNxiIiIruLlbm3v+rvvEBERtRobOcfeLu48R0RERK2jXfXYiYiITIZD8URERFZEgJGJvdUiMSkOxRMREVkR9tiJiMg2cCieiIjIimg0ADQ3rXbj9u0fh+KJiIisCHvsRERkGzgUT0REZEVsJLFzKJ6IiMiKsMdORES2wUZuKcvETkRENkEQNBCEls9sN6ZtW2JiJyIi2yAIxvW6eY6diIiI2hp77EREZBsEI8+xW0iPnYmdiIhsg0YDiIw4T24h59g5FE9ERGRF2GMnIiLbwKF4IiIi6yFoNBCMGIq3lMvdOBRPRERkRdhjJyIi28CheCIiIiuiEQCR9Sd2DsUTERFZEfbYiYjINggCAGOuY7eMHjsTOxER2QRBI0AwYiheYGInIiJqRwQNjOux83I3IiIim5eQkICgoCDIZDKEh4djz549N6y/a9cuhIeHQyaToWvXrli5cmWztsfETkRENkHQCEYvzbV+/XrMmzcPCxYsQGpqKoYPH47o6GhkZWXprZ+ZmYlx48Zh+PDhSE1Nxauvvoq5c+diw4YNBm+TiZ2IiGyDoDF+aaZly5YhJiYGM2bMQEhICOLj4xEQEIAVK1borb9y5Up07twZ8fHxCAkJwYwZM/D444/jvffeM3ibFn2O/epEBrWy1syRtH8qod7cIZAVUdfxM2cITY1lTLYyJ01tw3upLSamqVBv1P1pVGj4Hi0vL9cpl0qlkEqljerX1dUhJSUFr7zyik55VFQU9u/fr3cbf/31F6KionTKxo4di88++wz19fWwt7e/aZwWndgrKioAAGdXLDFzJO3fKXMHQNbls83mjoCsTEVFBRQKhUnW7eDggA4dOmBvXqLR63JxcUFAQIBO2cKFC7Fo0aJGdYuKiqBWq+Hr66tT7uvri7y8PL3rz8vL01tfpVKhqKgIfn5+N43RohO7v78/srOz4erqCpFIZO5wADT8kgsICEB2djbkcrm5w2m3eJwMw+NkGB4nw7TH4yQIAioqKuDv72+ybchkMmRmZqKurs7odQmC0Cjf6Out/9v19fWt42b19ZU3xaITu52dHTp16mTuMPSSy+Xt5oPTnvE4GYbHyTA8ToZpb8fJVD31f5PJZJDJZCbfzr95eXlBLBY36p0XFBQ06pVf1aFDB731JRIJPD09DdouJ88RERGZgIODA8LDw5GUlKRTnpSUhKFDh+ptExkZ2aj+jh07EBERYdD5dYCJnYiIyGTmz5+PTz/9FJ9//jkyMjLw3HPPISsrC7NmzQIAxMbGYtq0adr6s2bNwsWLFzF//nxkZGTg888/x2effYYXXnjB4G1a9FB8eySVSrFw4cKbnnOxdTxOhuFxMgyPk2F4nNre5MmTUVxcjCVLliA3NxehoaFITExEYGAgACA3N1fnmvagoCAkJibiueeew8cffwx/f3988MEHuO+++wzepkiwlJvfEhER0U1xKJ6IiMiKMLETERFZESZ2IiIiK8LETkREZEWY2FtZcx/PZ2t2796NCRMmwN/fHyKRCJs2bTJ3SO1SXFwcBg0aBFdXV/j4+GDSpEk4dYo3Bv63FStWICwsTHuzlcjISPz666/mDqvdi4uLg0gkwrx588wdCpkIE3srau7j+WxRVVUV+vXrh48++sjcobRru3btwpw5c3DgwAEkJSVBpVIhKioKVVVV5g6t3ejUqRPefvttJCcnIzk5GXfccQcmTpyItLQ0c4fWbh06dAirV69GWFiYuUMhE+Llbq1o8ODBGDhwoM7j+EJCQjBp0iTExcWZMbL2SSQS4aeffsKkSZPMHUq7V1hYCB8fH+zatQsjRowwdzjtloeHB/7v//4PMTEx5g6l3amsrMTAgQORkJCApUuXon///oiPjzd3WGQC7LG3kquP57v+cXs3ejwfkaHKysoANCQuakytVuO7775DVVUVIiMjzR1OuzRnzhyMHz8eo0ePNncoZGK881wracnj+YgMIQgC5s+fj1tvvRWhoaHmDqddOX78OCIjI1FbWwsXFxf89NNP6N27t7nDane+++47pKSkIDk52dyhUBtgYm9lzX08H9HNPP300zh27Bj27t1r7lDaneDgYBw5cgSlpaXYsGEDpk+fjl27djG5/0t2djaeffZZ7Nixo82fbkbmwcTeSlryeD6im3nmmWewZcsW7N69u90+oticHBwc0L17dwBAREQEDh06hOXLl2PVqlVmjqz9SElJQUFBAcLDw7VlarUau3fvxkcffQSlUgmxWGzGCKm18Rx7K2nJ4/mImiIIAp5++mls3LgRf/zxB4KCgswdkkUQBAFKpdLcYbQro0aNwvHjx3HkyBHtEhERgYcffhhHjhxhUrdC7LG3ovnz52Pq1KmIiIhAZGQkVq9erfN4PmqYmXv27Fnt68zMTBw5cgQeHh7o3LmzGSNrX+bMmYNvvvkGmzdvhqurq3YkSKFQwNHR0czRtQ+vvvoqoqOjERAQgIqKCnz33XfYuXMntm3bZu7Q2hVXV9dGczOcnZ3h6enJORtWiom9Fd3s8XwEJCcn4/bbb9e+nj9/PgBg+vTpWLt2rZmian+uXjI5cuRInfI1a9bg0UcfbfuA2qH8/HxMnToVubm5UCgUCAsLw7Zt2zBmzBhzh0ZkVryOnYiIyIrwHDsREZEVYWInIiKyIkzsREREVoSJnYiIyIowsRMREVkRJnYiIiIrwsRORERkRZjYiYy0aNEi9O/fX/v60UcfNcsz5i9cuACRSIQjR440WadLly7Negb32rVr4ebmZnRsIpEImzZtMno9RHRzTOxklR599FGIRCKIRCLY29uja9eueOGFF1BVVWXybS9fvtzgu+gZkoyJiJqDt5Qlq3XnnXdizZo1qK+vx549ezBjxgxUVVVpb9f6b/X19bC3t2+V7SoUilZZDxFRS7DHTlZLKpWiQ4cOCAgIwJQpU/Dwww9rh4OvDp9//vnn6Nq1K6RSKQRBQFlZGZ544gn4+PhALpfjjjvuwNGjR3XW+/bbb8PX1xeurq6IiYlBbW2tzt+vH4rXaDR455130L17d0ilUnTu3BlvvvkmAGif2jZgwACIRCKde8OvWbMGISEhkMlk6NWrFxISEnS2c/DgQQwYMAAymQwRERFITU1t9jFatmwZ+vbtC2dnZwQEBGD27NmorKxsVG/Tpk3o2bMnZDIZxowZg+zsbJ2///zzzwgPD4dMJkPXrl2xePFiqFSqZsdDRMZjYieb4ejoiPr6eu3rs2fP4vvvv8eGDRu0Q+Hjx49HXl4eEhMTkZKSgoEDB2LUqFG4cuUKAOD777/HwoUL8eabbyI5ORl+fn6NEu71YmNj8c477+D1119Heno6vvnmG/j6+gJoSM4A8NtvvyE3NxcbN24EAHzyySdYsGAB3nzzTWRkZOCtt97C66+/ji+++AIAUFVVhbvuugvBwcFISUnBokWL8MILLzT7mNjZ2eGDDz7AiRMn8MUXX+CPP/7ASy+9pFOnuroab775Jr744gvs27cP5eXleOihh7R/3759Ox555BHMnTsX6enpWLVqFdauXav98UJEbUwgskLTp08XJk6cqH39999/C56ensKDDz4oCIIgLFy4ULC3txcKCgq0dX7//XdBLpcLtbW1Ouvq1q2bsGrVKkEQBCEyMlKYNWuWzt8HDx4s9OvXT++2y8vLBalUKnzyySd648zMzBQACKmpqTrlAQEBwjfffKNT9t///leIjIwUBEEQVq1aJXh4eAhVVVXav69YsULvuv4tMDBQeP/995v8+/fffy94enpqX69Zs0YAIBw4cEBblpGRIQAQ/v77b0EQBGH48OHCW2+9pbOeL7/8UvDz89O+BiD89NNPTW6XiFoPz7GT1frll1/g4uIClUqF+vp6TJw4ER9++KH274GBgfD29ta+TklJQWVlJTw9PXXWU1NTg3PnzgEAMjIyMGvWLJ2/R0ZG4s8//9QbQ0ZGBpRKJUaNGmVw3IWFhcjOzkZMTAxmzpypLVepVNrz9xkZGejXrx+cnJx04miuP//8E2+99RbS09NRXl4OlUqF2tpaVFVVwdnZGQAgkUgQERGhbdOrVy+4ubkhIyMDt9xyC1JSUnDo0CGdHrparUZtbS2qq6t1YiQi02NiJ6t1++23Y8WKFbC3t4e/v3+jyXFXE9dVGo0Gfn5+2LlzZ6N1tfSSL0dHx2a30Wg0ABqG4wcPHqzzN7FYDAAQWuFpyxcvXsS4ceMwa9Ys/Pe//4WHhwf27t2LmJgYnVMWQMPlate7WqbRaLB48WLce++9jerIZDKj4ySi5mFiJ6vl7OyM7t27G1x/4MCByMvLg0QiQZcuXfTWCQkJwYEDBzBt2jRt2YEDB5pcZ48ePeDo6Ijff/8dM2bMaPR3BwcHAA093Kt8fX3RsWNHnD9/Hg8//LDe9fbu3RtffvklampqtD8ebhSHPsnJyVCpVPjf//4HO7uG6Tbff/99o3oqlQrJycm45ZZbAACnTp1CaWkpevXqBaDhuJ06dapZx5qITIeJnegfo0ePRmRkJCZNmoR33nkHwcHBuHz5MhITEzFp0iRERETg2WefxfTp0xEREYFbb70VX3/9NdLS0tC1a1e965TJZHj55Zfx0ksvwcHBAcOGDUNhYSHS0tIQExMDHx8fODo6Ytu2bejUqRNkMhkUCgUWLVqEuXPnQi6XIzo6GkqlEsnJySgpKcH8+fMxZcoULFiwADExMXjttddw4cIFvPfee83a327dukGlUuHDDz/EhAkTsG/fPqxcubJRPXt7ezzzzDP44IMPYG9vj6effhpDhgzRJvo33ngDd911FwICAvDAAw/Azs4Ox44dw/Hjx7F06dLm/0MQkVE4K57oHyKRCImJiRgxYgQef/xx9OzZEw899BAuXLigncU+efJkvPHGG3j55ZcRHh6Oixcv4qmnnrrhel9//XU8//zzeOONNxASEoLJkyejoKAAQMP56w8++ACrVq2Cv78/Jk6cCACYMWMGPv30U6xduxZ9+/bFbbfdhrVr12ovj3NxccHPP/+M9PR0DBgwAAsWLMA777zTrP3t378/li1bhnfeeQehoaH4+uuvERcX16iek5MTXn75ZUyZMgWRkZFwdHTEd999p/372LFj8csvvyApKQmDBg3CkCFDsGzZMgQGBjYrHiJqHSKhNU7WERERUbvAHjsREZEVYWInIiKyIkzsREREVoSJnYiIyIowsRMREVkRJnYiIiIrwsRORERkRZjYiYiIrAgTOxERkRVhYiciIrIiTOxERERWhImdiIjIivw/0DghL60Y6n4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, ensemble_pred, normalize=\"true\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Learning with Weighted Average!\n",
    "\n",
    "Based on classifier performance\n",
    "\n",
    "https://machinelearningmastery.com/weighted-average-ensemble-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average F1 macro: 46.764044016420506\n",
      "Voting Classifier with Weighted Average and 9-fold cv f1 macro avg: 0.5828\n",
      "Voting Classifier with Weighted Average and 9-fold cv f1 macro std: 0.0513\n"
     ]
    }
   ],
   "source": [
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('svm', SVC(random_state=rand_seed)))\n",
    "    models.append(('lr', LogisticRegression(random_state=rand_seed, max_iter=1000)))\n",
    "    models.append(('dt', DecisionTreeClassifier(random_state=rand_seed, max_depth=8)))\n",
    "    models.append(('nb', GaussianNB()))\n",
    "    models.append(('knn', KNeighborsClassifier(n_neighbors=5)))\n",
    "    return models\n",
    "\n",
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    # fit and evaluate models\n",
    "    scores = list()\n",
    "    for name, model in models:\n",
    "        # fit the classifiers\n",
    "        model.fit(X_train, y_train)\n",
    "        # eval model\n",
    "        ypred = model.predict(X_test)\n",
    "        f1_macro_score = f1_score(y_test, ypred, average=\"macro\")\n",
    "        # store performance\n",
    "        scores.append(f1_macro_score)\n",
    "    # report model performance\n",
    "    return scores\n",
    "\n",
    "# get the base models\n",
    "models = get_models()\n",
    "# fit and eval each model\n",
    "scores = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "precision\n",
    "\n",
    "# Create ensemble\n",
    "voting_ensemble = VotingClassifier(estimators=models, voting='hard', weights=scores)\n",
    "# Fit the ensemble to the training dataset\n",
    "voting_ensemble_clf = voting_ensemble.fit(X_train, y_train)\n",
    "voting_ensemble_pred = voting_ensemble_clf.predict(X_test)\n",
    "# Evaluate predictions\n",
    "score = f1_score(y_test, voting_ensemble_pred, average=\"macro\")\n",
    "print(f\"Weighted Average F1 macro: {score*100}\")\n",
    "\n",
    "# Use cross validation for evaluation\n",
    "cv_scores = cross_val_score(voting_ensemble_clf, X_train, y_train, cv=9,\n",
    "    scoring=\"f1_macro\")\n",
    "avg_cv_scores = np.average(cv_scores)\n",
    "std_cv_scores = np.std(cv_scores)\n",
    "print(f\"Voting Classifier with Weighted Average and 9-fold cv f1 macro avg: {avg_cv_scores:.4f}\")\n",
    "print(f\"Voting Classifier with Weighted Average and 9-fold cv f1 macro std: {std_cv_scores:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5697, k=5\n",
    "0.5931, k=6\n",
    "0.5619, k=7\n",
    "0.5604, k=8\n",
    "0.5788, k=9\n",
    "0.5752, k=10\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pattern-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1895724e0ba1d87308f72752509c0d197b6cd14cd38e9b4860259e222d188bca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
