{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Sklearn ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Initialize k-fold value\n",
    "k=5\n",
    "# Initialize variable for first test/train split\n",
    "test_percent = 1/(k+1)\n",
    "#test_percent = 0.2\n",
    "print(test_percent)\n",
    "\n",
    "# Mahalanobis threshold\n",
    "m_thresh = 0.05\n",
    "\n",
    "# Use same random seed to ensure reproducible results across runs\n",
    "rand_seed = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>class</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f1014</th>\n",
       "      <th>f1015</th>\n",
       "      <th>f1016</th>\n",
       "      <th>f1017</th>\n",
       "      <th>f1018</th>\n",
       "      <th>f1019</th>\n",
       "      <th>f1020</th>\n",
       "      <th>f1021</th>\n",
       "      <th>f1022</th>\n",
       "      <th>f1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZYURRE527</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.284965</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680631</td>\n",
       "      <td>-1.153061</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.162622</td>\n",
       "      <td>-1.085265</td>\n",
       "      <td>-0.657002</td>\n",
       "      <td>-1.406191</td>\n",
       "      <td>2.240085</td>\n",
       "      <td>0.118616</td>\n",
       "      <td>-0.728013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZWNWBP435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.045820</td>\n",
       "      <td>-0.216762</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.241972</td>\n",
       "      <td>-0.115316</td>\n",
       "      <td>-0.411191</td>\n",
       "      <td>0.431461</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>1.243681</td>\n",
       "      <td>-0.151721</td>\n",
       "      <td>0.458508</td>\n",
       "      <td>1.931918</td>\n",
       "      <td>-0.241081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZVHEZA963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>-0.292385</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>-0.792833</td>\n",
       "      <td>-0.471358</td>\n",
       "      <td>0.514799</td>\n",
       "      <td>-0.846220</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>-0.730218</td>\n",
       "      <td>1.352716</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.163302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ZSFNU1100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>-0.109248</td>\n",
       "      <td>-0.183284</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047666</td>\n",
       "      <td>-0.201043</td>\n",
       "      <td>-0.565545</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>-0.332314</td>\n",
       "      <td>-0.066972</td>\n",
       "      <td>-1.263785</td>\n",
       "      <td>3.876905</td>\n",
       "      <td>-0.397950</td>\n",
       "      <td>-0.693763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ZRXUB1049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>-0.068301</td>\n",
       "      <td>-0.283487</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221178</td>\n",
       "      <td>-0.253239</td>\n",
       "      <td>-0.046740</td>\n",
       "      <td>0.242367</td>\n",
       "      <td>-0.379724</td>\n",
       "      <td>-0.893249</td>\n",
       "      <td>-0.957397</td>\n",
       "      <td>1.118245</td>\n",
       "      <td>0.181925</td>\n",
       "      <td>-0.024197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>AGHXWX765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>-0.093583</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260746</td>\n",
       "      <td>-0.741712</td>\n",
       "      <td>-0.887129</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>0.216271</td>\n",
       "      <td>0.490549</td>\n",
       "      <td>-1.047399</td>\n",
       "      <td>1.875185</td>\n",
       "      <td>0.345561</td>\n",
       "      <td>-0.874318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>AFEOPC672</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>-0.302020</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457373</td>\n",
       "      <td>-0.782917</td>\n",
       "      <td>-1.072765</td>\n",
       "      <td>1.180279</td>\n",
       "      <td>-0.111142</td>\n",
       "      <td>1.897755</td>\n",
       "      <td>-0.902370</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>-0.314270</td>\n",
       "      <td>-1.198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>AEEEIG737</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>-0.152744</td>\n",
       "      <td>-0.355706</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411773</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>-0.527885</td>\n",
       "      <td>-0.305296</td>\n",
       "      <td>-0.189008</td>\n",
       "      <td>-0.592684</td>\n",
       "      <td>-1.144780</td>\n",
       "      <td>3.459698</td>\n",
       "      <td>-0.199579</td>\n",
       "      <td>-0.999165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>425</td>\n",
       "      <td>ADQRPH513</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>-0.092386</td>\n",
       "      <td>-0.434045</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147889</td>\n",
       "      <td>1.168724</td>\n",
       "      <td>-0.486698</td>\n",
       "      <td>1.134707</td>\n",
       "      <td>-0.029372</td>\n",
       "      <td>0.092189</td>\n",
       "      <td>-0.791921</td>\n",
       "      <td>1.786787</td>\n",
       "      <td>2.089036</td>\n",
       "      <td>-0.690614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>ABNTSS552</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.047733</td>\n",
       "      <td>-0.071875</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064665</td>\n",
       "      <td>-0.444786</td>\n",
       "      <td>-0.879349</td>\n",
       "      <td>1.048909</td>\n",
       "      <td>0.213126</td>\n",
       "      <td>1.170847</td>\n",
       "      <td>-1.172747</td>\n",
       "      <td>1.686595</td>\n",
       "      <td>0.482523</td>\n",
       "      <td>-0.440434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        uid  class        f0        f1        f2        f3  \\\n",
       "0             0  ZYURRE527      4  0.000462  0.005583 -0.001031  0.002307   \n",
       "1             1  ZWNWBP435      0  0.000220  0.006780 -0.000547  0.002183   \n",
       "2             2  ZVHEZA963      4  0.000405  0.007183 -0.000137  0.002612   \n",
       "3             3  ZSFNU1100      4  0.000388  0.003802  0.002121  0.001513   \n",
       "4             4  ZRXUB1049      0  0.000425  0.006544  0.001630  0.001549   \n",
       "..          ...        ...    ...       ...       ...       ...       ...   \n",
       "422         422  AGHXWX765      0  0.000305  0.003671 -0.004093  0.003010   \n",
       "423         423  AFEOPC672      3  0.000441  0.006178 -0.000811  0.003572   \n",
       "424         424  AEEEIG737      3  0.000464  0.006611  0.000842  0.001412   \n",
       "425         425  ADQRPH513      3  0.000233  0.003029  0.001606  0.001224   \n",
       "426         426  ABNTSS552      4  0.000233  0.006601 -0.001318  0.001098   \n",
       "\n",
       "           f4        f5        f6  ...     f1014     f1015     f1016  \\\n",
       "0   -0.113097 -0.284965  0.001069  ...  0.680631 -1.153061  0.111816   \n",
       "1   -0.045820 -0.216762  0.000987  ... -1.241972 -0.115316 -0.411191   \n",
       "2   -0.083430 -0.292385  0.001094  ...  0.659314 -0.792833 -0.471358   \n",
       "3   -0.109248 -0.183284  0.000813  ... -0.047666 -0.201043 -0.565545   \n",
       "4   -0.068301 -0.283487  0.001004  ... -1.221178 -0.253239 -0.046740   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "422 -0.093583  0.133018  0.000627  ... -0.260746 -0.741712 -0.887129   \n",
       "423 -0.108863 -0.302020  0.000761  ...  0.457373 -0.782917 -1.072765   \n",
       "424 -0.152744 -0.355706  0.000906  ...  0.411773  0.232481 -0.527885   \n",
       "425 -0.092386 -0.434045  0.000668  ... -0.147889  1.168724 -0.486698   \n",
       "426 -0.047733 -0.071875  0.000654  ... -0.064665 -0.444786 -0.879349   \n",
       "\n",
       "        f1017     f1018     f1019     f1020     f1021     f1022     f1023  \n",
       "0    0.162622 -1.085265 -0.657002 -1.406191  2.240085  0.118616 -0.728013  \n",
       "1    0.431461  0.442649  1.243681 -0.151721  0.458508  1.931918 -0.241081  \n",
       "2    0.514799 -0.846220  0.479314 -0.730218  1.352716  0.040223 -0.163302  \n",
       "3    0.999009 -0.332314 -0.066972 -1.263785  3.876905 -0.397950 -0.693763  \n",
       "4    0.242367 -0.379724 -0.893249 -0.957397  1.118245  0.181925 -0.024197  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "422  0.190525  0.216271  0.490549 -1.047399  1.875185  0.345561 -0.874318  \n",
       "423  1.180279 -0.111142  1.897755 -0.902370  0.552967 -0.314270 -1.198762  \n",
       "424 -0.305296 -0.189008 -0.592684 -1.144780  3.459698 -0.199579 -0.999165  \n",
       "425  1.134707 -0.029372  0.092189 -0.791921  1.786787  2.089036 -0.690614  \n",
       "426  1.048909  0.213126  1.170847 -1.172747  1.686595  0.482523 -0.440434  \n",
       "\n",
       "[427 rows x 1027 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in dataset\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of feature names\n",
    "feature_names = [name for name in df.columns if name.startswith(\"f\")]\n",
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    132\n",
       "4     91\n",
       "3     65\n",
       "1     45\n",
       "2     22\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    27\n",
       "4    18\n",
       "3    13\n",
       "1     9\n",
       "2     5\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = df[feature_names]\n",
    "y_all = df[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_percent, random_state=rand_seed, stratify=y_all\n",
    ")\n",
    "\n",
    "# Reset train index\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Training set by class:\")\n",
    "display(y_train.value_counts())\n",
    "print(\"Test set by class:\")\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Data\n",
    "\n",
    "Use StandardScaler from sklearn. Standardize both X_train and X_test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scaler\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "# Fit and transform scaling to training data\n",
    "X_train = scaler_std.fit_transform(X_train)\n",
    "# Transform testing data using same fit\n",
    "X_test = scaler_std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get single training DataFrame\n",
    "# norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "# norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "# # Standardize X_train values\n",
    "# X_train = norm_data(norm_df[feature_names])\n",
    "\n",
    "# # Get single testing DataFrame\n",
    "# norm_xtest_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "# norm_test_df = pd.concat([y_test, norm_x_df], axis=1)\n",
    "# # Standardize X_test values (for later)\n",
    "# X_test = norm_data(norm_test_df[feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers\n",
    "\n",
    "Since we are in multi-dimensional space, we will use the mean and covariance matrices. This will be computed using Mahalanobis distance which is well-suited for multi-dimensional space: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that computes mean, cov matrix, and inv cov matrix\n",
    "def get_mean_cov(X_train):\n",
    "    # Merge dfs\n",
    "    norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "    norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "    # Compute mean and cov per class per feature\n",
    "    avg_list = []\n",
    "    cov_list = []\n",
    "    inv_cov_list = []\n",
    "    for i in range(5):\n",
    "        # Compute mean\n",
    "        avg = np.mean(norm_df[norm_df[\"class\"]==i][feature_names], axis=0)\n",
    "        avg_list.append(avg)\n",
    "        # Compute cov matrix\n",
    "        cov = np.cov(norm_df[norm_df[\"class\"]==i][feature_names], rowvar=False)\n",
    "        cov_list.append(cov)\n",
    "        # Compute inverse of cov matrix\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        inv_cov_list.append(inv_cov)\n",
    "    return norm_df, avg_list, inv_cov_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_mean_cov function\n",
    "norm_df, avg_list, inv_cov_list = get_mean_cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    355.000000\n",
       "mean      39.703241\n",
       "std       34.716815\n",
       "min        1.786194\n",
       "25%       20.046636\n",
       "50%       32.068333\n",
       "75%       45.081983\n",
       "max      280.206962\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 1675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which features should be removed (identify outliers based on Mahalanobis dist)\n",
    "# Create function that computes Mahalanobis distance and adds it to norm_df\n",
    "def get_mahalanobis_dist(label, features):\n",
    "    u = avg_list[label]\n",
    "    v = features\n",
    "    vi = inv_cov_list[label]\n",
    "    delta = u - v\n",
    "    m = np.dot(np.dot(delta, vi), delta)\n",
    "    #dist = distance.mahalanobis(u, features, vi)\n",
    "    return np.sqrt(np.abs(m))\n",
    "\n",
    "# Call function for each feature\n",
    "norm_df[\"mahalanobis_dist\"] = norm_df.apply(lambda row: get_mahalanobis_dist(int(row[\"class\"]), row[feature_names]), axis=1)\n",
    "norm_df[\"mahalanobis_dist\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "def drop_outliers(norm_df, threshold):\n",
    "    # Remove threshold% of outliers by class\n",
    "    for i in range(5):\n",
    "        # Get threshold% of outliers for each class\n",
    "        threshold_num = norm_df[norm_df[\"class\"]==i][\"mahalanobis_dist\"].quantile(1-threshold)\n",
    "        # Drop threshold% of outliers for each class\n",
    "        norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)        \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\AppData\\Local\\Temp\\ipykernel_14752\\977542497.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    317.000000\n",
       "mean      35.730002\n",
       "std       29.414170\n",
       "min        1.786194\n",
       "25%       18.827374\n",
       "50%       30.422501\n",
       "75%       41.279958\n",
       "max      205.869203\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 1677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test drop_outliers function\n",
    "norm_df = drop_outliers(norm_df, m_thresh)\n",
    "\n",
    "# Print updated descriptive stats\n",
    "norm_df[\"mahalanobis_dist\"].describe()\n",
    "#print(len(norm_df[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X_train and y_train\n",
    "X_train = norm_df[feature_names]\n",
    "y_train = norm_df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample Data\n",
    "\n",
    "Use ADASYN technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that oversamples or undersamples data\n",
    "def resample(sampler, X_train, y_train, name):\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "    # Observe number of classes after resample\n",
    "    #print(f\"Number of samples per class after {name}:\\n{y_train.value_counts()}\")\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resample function\n",
    "# Setup ADASYN (oversampling)\n",
    "ada = ADASYN(random_state=rand_seed, sampling_strategy=\"minority\", n_neighbors=4)\n",
    "\n",
    "# Call resample function\n",
    "X_train, y_train = resample(ada, X_train, y_train, \"ADASYN Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 1024)\n",
      "0    118\n",
      "2    113\n",
      "4     82\n",
      "3     58\n",
      "1     40\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "# List from Azure ML Designer (Filter Based Feature Selection)\n",
    "azureml_features = pd.read_csv(\"outputs/feature_selection/azureml_designer_features.csv\", header=None)\n",
    "# List from recursive feature elimination w/ and w/o cross-validation\n",
    "rfe_features = pd.read_csv(\"outputs/feature_selection/CommonFeatures_RFE_RFECV.csv\", header=None)\n",
    "\n",
    "rfe_features = rfe_features[0].to_numpy()\n",
    "#display(rfe_features)\n",
    "azureml_features = azureml_features[0].to_numpy()\n",
    "# display(azureml_features)\n",
    "\n",
    "# Get out common features\n",
    "common_features = np.union1d(azureml_features, rfe_features)\n",
    "extracted_feature_names = [f\"f{i}\" for i in common_features]\n",
    "#print(extracted_feature_names)\n",
    "#display(extracted_feature_names)\n",
    "print(np.count_nonzero(common_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training dataset with only\n",
    "# the subset of features included\n",
    "X_train = X_train[extracted_feature_names]\n",
    "#print(X_train)\n",
    "\n",
    "# Get testing dataset wiuth only\n",
    "# the subset of features included\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test = X_test[extracted_feature_names]\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters to try\n",
    "c_range = np.arange(5,4000)\n",
    "params = {\n",
    "    'C': c_range,\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Setup classifier\n",
    "svm = SVC(random_state=rand_seed)\n",
    "# Configure random search from sklearn\n",
    "svm_clf = RandomizedSearchCV(svm, params, scoring='f1_macro', cv=k, random_state=rand_seed)\n",
    "# Perform hyperparameter search\n",
    "search = svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'gamma': 'auto', 'C': 382}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083894</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>721</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 721}</td>\n",
       "      <td>0.570569</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.586316</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082976</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>303</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 303}</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>0.639471</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.441383</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080674</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>1596</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}</td>\n",
       "      <td>0.570569</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.586316</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081617</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>931</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 931}</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>0.639471</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.441383</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067963</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>382</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 382}</td>\n",
       "      <td>0.629713</td>\n",
       "      <td>0.623214</td>\n",
       "      <td>0.589308</td>\n",
       "      <td>0.545775</td>\n",
       "      <td>0.631144</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.082542</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.029702</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2022</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>0.639471</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.441383</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080953</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.029475</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>2352</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}</td>\n",
       "      <td>0.570569</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.586316</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.029898</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>650</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 650}</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>0.639471</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.441383</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.081791</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.028992</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>3159</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>0.639471</td>\n",
       "      <td>0.599652</td>\n",
       "      <td>0.441383</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>0.580933</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.069698</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>1969</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 1969}</td>\n",
       "      <td>0.629713</td>\n",
       "      <td>0.623214</td>\n",
       "      <td>0.589308</td>\n",
       "      <td>0.545775</td>\n",
       "      <td>0.631144</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.083894      0.006276         0.027786        0.001236          rbf   \n",
       "1       0.082976      0.002420         0.029653        0.001053          rbf   \n",
       "2       0.080674      0.002423         0.028028        0.000743          rbf   \n",
       "3       0.081617      0.002910         0.028275        0.001208          rbf   \n",
       "4       0.067963      0.001854         0.023392        0.001183       linear   \n",
       "5       0.082542      0.001070         0.029702        0.002642          rbf   \n",
       "6       0.080953      0.003389         0.029475        0.001829          rbf   \n",
       "7       0.081629      0.001906         0.029898        0.002522          rbf   \n",
       "8       0.081791      0.000984         0.028992        0.001583          rbf   \n",
       "9       0.069698      0.004156         0.030826        0.015196       linear   \n",
       "\n",
       "  param_gamma param_C                                            params  \\\n",
       "0        auto     721      {'kernel': 'rbf', 'gamma': 'auto', 'C': 721}   \n",
       "1       scale     303     {'kernel': 'rbf', 'gamma': 'scale', 'C': 303}   \n",
       "2        auto    1596     {'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}   \n",
       "3       scale     931     {'kernel': 'rbf', 'gamma': 'scale', 'C': 931}   \n",
       "4        auto     382   {'kernel': 'linear', 'gamma': 'auto', 'C': 382}   \n",
       "5       scale    2022    {'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}   \n",
       "6        auto    2352     {'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}   \n",
       "7       scale     650     {'kernel': 'rbf', 'gamma': 'scale', 'C': 650}   \n",
       "8       scale    3159    {'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}   \n",
       "9        auto    1969  {'kernel': 'linear', 'gamma': 'auto', 'C': 1969}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.570569           0.625570           0.599652           0.491361   \n",
       "1           0.579731           0.639471           0.599652           0.441383   \n",
       "2           0.570569           0.625570           0.599652           0.491361   \n",
       "3           0.579731           0.639471           0.599652           0.441383   \n",
       "4           0.629713           0.623214           0.589308           0.545775   \n",
       "5           0.579731           0.639471           0.599652           0.441383   \n",
       "6           0.570569           0.625570           0.599652           0.491361   \n",
       "7           0.579731           0.639471           0.599652           0.441383   \n",
       "8           0.579731           0.639471           0.599652           0.441383   \n",
       "9           0.629713           0.623214           0.589308           0.545775   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.644431         0.586316        0.053592                3  \n",
       "1           0.644431         0.580933        0.073871                6  \n",
       "2           0.644431         0.586316        0.053592                3  \n",
       "3           0.644431         0.580933        0.073871                6  \n",
       "4           0.631144         0.603831        0.032781                1  \n",
       "5           0.644431         0.580933        0.073871                6  \n",
       "6           0.644431         0.586316        0.053592                3  \n",
       "7           0.644431         0.580933        0.073871                6  \n",
       "8           0.644431         0.580933        0.073871                6  \n",
       "9           0.631144         0.603831        0.032781                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_params)\n",
    "#display(search.cv_results_)\n",
    "\n",
    "hyperparam_results_df = pd.DataFrame(search.cv_results_)\n",
    "display(hyperparam_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_classifier_with_k_folds(classifier, n_splits=5, random_state=rand_seed):\n",
    "    classifiers = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        classifiers.append(classifier)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_fold)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "        precision_scores.append(\n",
    "            precision_score(y_test_fold, y_pred, average=\"macro\")\n",
    "        )\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "\n",
    "    return classifiers, {\n",
    "        \"accuracy\": pd.Series(accuracy_scores).describe().to_dict(),\n",
    "        \"f1\": pd.Series(f1_scores).describe().to_dict(),\n",
    "        \"precision\": pd.Series(precision_scores).describe().to_dict(),\n",
    "        \"recall\": pd.Series(recall_scores).describe().to_dict(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255)],\n",
       " {'accuracy': {'count': 5.0,\n",
       "   'mean': 0.6886276814575375,\n",
       "   'std': 0.038405809373713,\n",
       "   'min': 0.6463414634146342,\n",
       "   '25%': 0.6626506024096386,\n",
       "   '50%': 0.6829268292682927,\n",
       "   '75%': 0.7073170731707317,\n",
       "   'max': 0.7439024390243902},\n",
       "  'f1': {'count': 5.0,\n",
       "   'mean': 0.621788422671802,\n",
       "   'std': 0.04575224813701675,\n",
       "   'min': 0.5879750433897899,\n",
       "   '25%': 0.5978479853479853,\n",
       "   '50%': 0.6074709456656426,\n",
       "   '75%': 0.6139238539238538,\n",
       "   'max': 0.7017242850317384},\n",
       "  'precision': {'count': 5.0,\n",
       "   'mean': 0.6462865021701604,\n",
       "   'std': 0.05053383449166561,\n",
       "   'min': 0.5842307692307693,\n",
       "   '25%': 0.6281379310344828,\n",
       "   '50%': 0.6398757763975155,\n",
       "   '75%': 0.6561111111111111,\n",
       "   'max': 0.7230769230769231},\n",
       "  'recall': {'count': 5.0,\n",
       "   'mean': 0.616180345656049,\n",
       "   'std': 0.04358625413150874,\n",
       "   'min': 0.5888746803069054,\n",
       "   '25%': 0.5965909090909091,\n",
       "   '50%': 0.5977272727272728,\n",
       "   '75%': 0.6041666666666667,\n",
       "   'max': 0.693542199488491}})"
      ]
     },
     "execution_count": 1687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "analyze_classifier_with_k_folds(svm_final_clf, n_splits=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4861\n",
      "F1 macro score: 0.5130\n",
      "Precision: 0.5608\n",
      "Recall: 0.4989\n"
     ]
    }
   ],
   "source": [
    "# Fit model using best hyperparameters found in previous search\n",
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "svm_model_final = svm_final_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model_final.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 macro score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Meta Learning!\n",
    "\n",
    "In addition to the svm classifier above (svm), we'll use the VotingClassifier() from sklearn which takes multiple estimators as input, and implements a voting procedure. We will use the following classifiers:\n",
    "\n",
    "- SVM (already created)\n",
    "- Naive Bayes\n",
    "- kNN, k=5\n",
    "- Decision Tree, max depth = 8\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the classifiers!\n",
    "# Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# kNN, k=5\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Decision tree, max depth=8\n",
    "dt_clf = DecisionTreeClassifier(random_state=rand_seed, max_depth=8)\n",
    "\n",
    "# Logistic regression\n",
    "lr_clf = LogisticRegression(random_state=rand_seed, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.5417\n",
      "Ensemble F1 macro score: 0.5478\n",
      "Ensemble precision: 0.6044\n",
      "Ensemble recall: 0.5254\n"
     ]
    }
   ],
   "source": [
    "# Put them to a vote!\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), ('nb', nb_clf), ('knn', knn_clf),\n",
    "    ('dt', dt_clf), ('lr', lr_clf)], voting='hard'\n",
    ")\n",
    "\n",
    "# Fit and predict with voting classifier\n",
    "ensemble_clf = ensemble_clf.fit(X_train, y_train)\n",
    "ensemble_pred = ensemble_clf.predict(X_test)\n",
    "\n",
    "# Get metrics\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_precision = precision_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_recall = recall_score(y_test, ensemble_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Ensemble accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"Ensemble F1 macro score: {ensemble_f1:.4f}\")\n",
    "print(f\"Ensemble precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Ensemble recall: {ensemble_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23729ac7f40>"
      ]
     },
     "execution_count": 1697,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, ensemble_pred, normalize=\"true\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pattern-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1895724e0ba1d87308f72752509c0d197b6cd14cd38e9b4860259e222d188bca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
